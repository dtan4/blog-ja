<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Docker on blog-ja.dtan4.net</title><link>http://blog-ja.dtan4.net/tags/docker/</link><description>Recent content in Docker on blog-ja.dtan4.net</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><copyright>Copyright &amp;copy; 2020 dtan4 All Rights Reserved</copyright><lastBuildDate>Mon, 03 Oct 2016 00:00:00 +0000</lastBuildDate><atom:link href="http://blog-ja.dtan4.net/tags/docker/index.xml" rel="self" type="application/rss+xml"/><item><title>EC2 + IAM Role で供給されたクレデンシャルを環境変数として使う</title><link>http://blog-ja.dtan4.net/posts/qiita-4f687a74abcbe1a36190/</link><pubDate>Mon, 03 Oct 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-4f687a74abcbe1a36190/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
2016-12-09 14:15 追記 EC2 上の Docker コンテナ内からでも、AWS_ 環境変数を設定することなくインスタンスプロファイルが使えました。
AWS SDK は AWS_* 環境変数設定されてなかったら自動で http://169.254.169.254/latest/meta-data/... を叩いてクレデンシャルを取りに行きます。で、ホスト直実行でもコンテナ挟むのでもつなぎに行くネットワークは同じ AWS なので問題なくインスタンスプロファイルを取れるのでした。
したがって、この記事に書いてあるような手間をかける必要はありません…
tl;dr AWS_SECURITY_TOKEN AWS_SESSION_TOKEN を忘れるな
2019-03-11 追記 awscli は AWS_SECURITY_TOKEN で実行できますが、 AWS SDK は AWS_SESSION_TOKEN でないと動作しないものがあるようです。 ログイン画面から発行されるワンタイムパスワードも現在は AWS_SESSION_TOKEN であるため、そちらに統一する方が良さそうです。
時代は IAM Role EC2 上で AWS リソースにアクセスする場合、専用の IAM ユーザを作ってクレデンシャルを発行してもいいのですが、IAM Role を EC2 に紐付けると便利です。クレデンシャルをアプリケーションコードやスクリプトに埋め込む必要がなくなるからです。
しかし awscli や AWS SDK を埋め込んだコードを__ホスト上で直に__実行する場合は彼らがよしなにクレデンシャルを取得するのでいいのですが、Docker コンテナ上で実行する場合は少々面倒です。-e AWS_ACCESS_KEY_ID= でクレデンシャルを渡したいのですが値はどこから取ればいいのか。
※ 今回は ECS 上ではなく1、直接インスタンス上で docker run する場合の話です。
metadata からクレデンシャルを取り出す EC2 インスタンス内部から http://169.</description></item><item><title>PostgreSQL が起動したかどうか簡単に確認する (ping)</title><link>http://blog-ja.dtan4.net/posts/qiita-45ae1a8ac6f853a0dc1a/</link><pubDate>Wed, 07 Sep 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-45ae1a8ac6f853a0dc1a/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
PostgreSQL は、プロセスを起動してから SQL クエリ・外部入力を受け付けるようになるまで若干のタイムラグが有ります。特に Docker コンテナで起動した場合、自分の環境では5秒程度待つことになります。
The files belonging to this database system will be owned by user &amp;quot;postgres&amp;quot;. This user must also own the server process. The database cluster will be initialized with locale &amp;quot;en_US.utf8&amp;quot;. The default database encoding has accordingly been set to &amp;quot;UTF8&amp;quot;. The default text search configuration will be set to &amp;quot;english&amp;quot;. ... LOG: autovacuum launcher shutting down LOG: shutting down LOG: database system is shut down done server stopped PostgreSQL init process complete; ready for start up.</description></item><item><title>CoreOS で ECS クラスタを構築する</title><link>http://blog-ja.dtan4.net/posts/qiita-a98ceb194ed4854bb300/</link><pubDate>Wed, 15 Jun 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-a98ceb194ed4854bb300/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
ECS クラスタを作るにあたって土台の EC2 インスタンスが必要となるわけですが、そこで使う AMI として公式では ECS-optimized AMI を推奨しています。ECS-optimized AMI は Amazon Linux AMI に新し目の Docker と ecs-agent、ecs-init スクリプトを同梱したやつです。初回チュートリアルでクラスタを立てる時もこの AMI が使われます。
ただ、実際のところ EC2 の中身に関しては (2016-06-15 時点)
Linux Kernel 3.10 以上で Docker 1.5.0 以上で ecs-agent コンテナが立ってる のであれば何でもよいのです。ECS-optimized AMI はそれを満たした推奨構成であるだけです。
というわけで、Docker 環境に特化した CoreOS を使ってみましょう。
ECS クラスタを準備 まっさらからクラスタ建てる場合は、Management Console なり ecs-cli なりで新しくクラスタを作ってください。 もしくは、既存クラスタにノード追加の形で CoreOS インスタンスを追加することもできます。
（ないなら）IAM Role ecsInstanceRole を作成 ecs-agent が ECS API にアクセスするため、その権限をインスタンスに付与してあげる必要があります。 初回チュートリアルでクラスタを立ち上げた場合は作られてると思いますが、まっさらからクラスタを構築する場合はこの Role がないので作る必要があります。
IAM -&amp;gt; Roles -&amp;gt; Create New Role を開く [AWS Service Role] の [Amazon EC2] を開き、AmazonEC2ContainerServiceforEC2Role にチェックを入れる [Create Role] 作った Role を開き、[Trusted Relationships] -&amp;gt; [Show policy document] が以下のようになっているのを確認。なってなかったら上書き。 { &amp;#34;Version&amp;#34;: &amp;#34;2008-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Sid&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: { &amp;#34;Service&amp;#34;: &amp;#34;ec2.</description></item><item><title>CoreOS で Docker デーモンの起動オプション DOCKER_OPTS を設定する</title><link>http://blog-ja.dtan4.net/posts/qiita-2212607d13ad7c81120e/</link><pubDate>Mon, 16 May 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-2212607d13ad7c81120e/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
CoreOS は何もしなくとも自動で Docker デーモンが立ち上がりますが、たまに Docker デーモン自体の起動オプション (DOCKER_OPTS) を設定したい時があります。Docker デーモンへのアクセスには TLS 認証使いたいとか、overlay network を使うための下準備をしたいとかです。
そういう時は、cloud-config の units に docker.service を記述することで Docker デーモンの起動時に DOCKER_OPTS を設定できます。 以下の例では、etcd を利用した overlay network 構築 のオプションを指定しています。
coreos: units: - name: etcd2.service command: start - name: docker.service # &amp;lt;===== drop-ins: - name: 10-cluster-config.conf content: | [Service] Environment=&amp;#34;DOCKER_OPTS=--cluster-store=etcd://0.0.0.0:2379 --cluster-advertise=eth0:2375&amp;#34; REF Customizing docker</description></item><item><title>Ubuntu や Alpine Linux をワンコマンドで瞬時に立ち上げる</title><link>http://blog-ja.dtan4.net/posts/qiita-3be396665f9305428f4f/</link><pubDate>Thu, 14 Apr 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-3be396665f9305428f4f/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
alpine コマンド、centos コマンド、ubuntu コマンド Docker 環境を用意して以下のエイリアスを .bashrc なり .zshrc に書いておくと、ワンコマンドで Linux の対話環境が立ち上がって便利
alias alpine=&amp;#39;docker run -it --rm alpine:3.3 /bin/sh&amp;#39; alias centos=&amp;#39;docker run -it --rm centos:7 /bin/bash&amp;#39; alias ubuntu=&amp;#39;docker run -it --rm ubuntu:14.04 /bin/bash&amp;#39; $ alpine / # apk update fetch http://dl-cdn.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz v3.3.3-20-gb700737 [http://dl-cdn.alpinelinux.org/alpine/v3.3/main] v3.3.3-9-gfc38db2 [http://dl-cdn.alpinelinux.org/alpine/v3.3/community] OK: 5858 distinct packages available $ centos [root@dfaaba07c44b /]# yum update Loaded plugins: fastestmirror, ovl base | 3.6 kB 00:00:00 extras | 3.</description></item><item><title>Alpine Linux でタイムゾーンを変更する</title><link>http://blog-ja.dtan4.net/posts/qiita-8359e389b95cbc60952d/</link><pubDate>Sat, 06 Feb 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-8359e389b95cbc60952d/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
スリムな Docker イメージを作るため、gliderlabs/alpine イメージをベースにバイナリを一個だけポンと置いて運用するみたいなことをしています。 gliderlabs/alpine イメージは（というかほとんどの OS イメージは）タイムゾーンが GMT (UTC+0) のままなので、時刻依存の作業をさせるときには気をつけないといけません。日本時間 (UTC+9) の感覚で書いたら、9時間遅れて実行されたとかログの時刻がずれるとか起こりえます。
まっさらの状態で date を打つと…
$ docker run --rm gliderlabs/alpine:3.3 date Sat Feb 6 06:47:37 UTC 2016 タイムゾーンの設定 メジャーな Linux ディストリビューションと同じく、/etc/localtime を変更すればよいです。zoneinfo とかはそのままだと用意されていないので、apk で tzdata パッケージをインストールする必要があります。
Dockerfile で日本標準時 Asia/Tokyo に設定する場合は以下のようになります。ここで欲しいのは /usr/share/zoneinfo/Asia/Tokyo だけなので、tzdata はそれだけ抜き取ったら消しちゃいます。
FROMgliderlabs/alpine:3.3RUN apk --update add tzdata &amp;amp;&amp;amp; \ cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \ apk del tzdata &amp;amp;&amp;amp; \ rm -rf /var/cache/apk/*この Dockerfile からビルドしたイメージで date を叩くと…</description></item><item><title>クラウドサービスを活用して README にバッジをペタペタ貼る</title><link>http://blog-ja.dtan4.net/posts/qiita-13b0ea9edf5b99926446/</link><pubDate>Sat, 31 Oct 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-13b0ea9edf5b99926446/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
最近の GitHub に上げてある OSS リポジトリには、README にいろんなバッジが貼られています。リポジトリに連携しているクラウドサービスのステータスを表すものがほとんどです。 自分は README にバッジを貼りたい派です。たとえば dtan4/terraforming だとこういう感じです。
最近はバッジの種類も増えているので、整理のためにもどういうのがあるかまとめてみようと思います。
自分がよく README に貼っているバッジ 自分が書く RubyGems については、以下の6個のバッジを必ずつけるようにしています。
Travis CI
言わずと知れた CI サービス。現在の master が CI 通っている (passing) かコケている (failed) かがわかります。リポジトリのメンテナンス状況を把握するのによいです。
クリックすれば、そのリポジトリのテスト結果を見ることができます。
Code Climate
ソースコードの品質チェックをしてくれるサービスです。リポジトリ内のコード重複や複雑性を解析して GPA (最高 4.0) を算出してくれます。このリポジトリのコード品質がどうであるか、をひと目で確認できます。Ruby の他にも Node.js や PHP, Python に対応してます。
最近はテストカバレッジの取得にも対応しました。Travis CI のテスト後にテストカバレッジが Code Climate へアップロードされます。 以前はテストカバレッジの表示に Coveralls を使っていましたが、Code Climate でひとまとめに見られるようになったので最近はこっちを使うようにしています。
クリックすれば、そのリポジトリの詳細な解析結果と行単位のテストカバレッジを見ることができます。
Gemnasium
アプリケーションの依存管理をチェックしてくれるサービスです。Ruby だと Gemfile, Gemfile.lock, *.gemspec を解析し、指定されている依存ライブラリのバージョンが古くなったら警告を出してくれます。Ruby の他にも Node.</description></item><item><title>PostgreSQL コンテナの backup / restore をする</title><link>http://blog-ja.dtan4.net/posts/qiita-5147a3f858d5919965c9/</link><pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-5147a3f858d5919965c9/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker コンテナとして動いている PostgreSQL からデータを backup する、またデータを restore する（PostgreSQL コンテナにデータを注入する）方法です。 ここで使っているイメージは Docker Hub 公式の postgres イメージです。今回は postgres:9.4.1 を使いました。
$ docker run -d -p 5432:5432 --name postgres postgres:9.4.1 backup する $ docker exec [container_id or name] pg_dumpall -U postgres &amp;gt; dump.sql コンテナ内のデータベース全体が SQL として dump されます。
-- -- PostgreSQL database cluster dump -- SET default_transaction_read_only = off; SET client_encoding = &amp;#39;UTF8&amp;#39;; SET standard_conforming_strings = on; -- -- Roles -- CREATE ROLE postgres; ALTER ROLE postgres WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN REPLICATION; .</description></item><item><title>開発版 Docker &amp; Docker Registry の検証環境を作って試してみる</title><link>http://blog-ja.dtan4.net/posts/qiita-0e34a09923579e7a6670/</link><pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-0e34a09923579e7a6670/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker イメージのリポジトリをを自前で管理するための Docker Private Registry というものがあります。これまで docker/docker-registry にて Python で開発されていて、現在のバージョンは 0.9.1 です。 この docker-registry、使っている Python の HTTP サーバが buggy なのか push/pull でよく失敗するという問題がありました…
ところで、この Docker Registry の次期バージョンは Go でスクラッチから開発されています。リポジトリも docker/distrbution に移りました。 最初のリリースバージョンは 2.0 になる予定で、しかもリリース日予定は 2015-04-16（たぶん西海岸時間）です。 なんだか期待が持てます :+1:
この registry v2 ですが、API も v1 -&amp;gt; v2 に上がっているので 現在リリースされている Docker 1.5 以下は対応していません（push/pull できない）。 registry v2 と同時リリースされる Docker 1.6 から対応する予定です。
=== 2015-04-16 18:40 追記 一応 README.md には Docker 1.5+ サポートするって書いてあるんですよね…
An implementation of the Docker Registry HTTP API V2 for use with docker 1.</description></item><item><title>CoreOS + flannel で複数ホスト間コンテナ通信をする</title><link>http://blog-ja.dtan4.net/posts/qiita-8f9cf40aabd2e6c9a494/</link><pubDate>Thu, 02 Apr 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-8f9cf40aabd2e6c9a494/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
CoreOS が提供する flannel を使って、複数の CoreOS マシンを跨いで Docker コンテナ同士通信できるようにする、というお話です。
flannel もともと Kubernates には似たようなホスト間通信機能がついていたのですが、Google Compute Engine (GCE) 上でしか使えないという欠点がありました。これを取り出し、汎用的に使えるようにしたのが flannel です。
また、似た機能を持つものに weave がありますが、weave は導入が少々面倒な上に相手ホストの IP を明示的に指定してあげないといけません。その点 flannel は CoreOS 上での導入が簡単で、相手の IP を知らなくてもよく透過的に利用できるという利点があります。ホストに割り振られる IP が不定である EC2 + VPC 構成でも使いやすいでしょう。
イメージ図はこんな感じです。
(from https://github.com/coreos/flannel/blob/master/packet-01.png)
試してみる 以下で紹介する CoreOS VM を含めたサンプルリポジトリです。あわせてご利用ください: dtan4/coreos-flannel-sample
cloud-config まず cloud-config はこんな感じです。flanneld.service というのを定義しています。
#cloud-config coreos: etcd: discovery: https://discovery.etcd.io/&amp;lt;token&amp;gt; addr: $public_ipv4:4001 peer-addr: $public_ipv4:7001 fleet: public-ip: $public_ipv4 flannel: interface: $public_ipv4 units: - name: etcd.service command: start - name: fleet.</description></item><item><title>Rack 1.6 な Sinatra アプリケーションに Docker コンテナ外からアクセスできなかった</title><link>http://blog-ja.dtan4.net/posts/qiita-c7c47b845b6f15c4076f/</link><pubDate>Wed, 21 Jan 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-c7c47b845b6f15c4076f/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
[2015-01-24 05:00] @5t111111 さんのコメントに基づき、Rack 1.6 のデフォルト挙動について追記 Rack 1.6.0 を使用した Sinatra アプリケーションを Docker 上で起動したところ、コンテナ外からの接続ができませんでした。EXPOSE 9292 して -p 9292:9292 しているにも関わらず、です。 とりあえずの対処法を書いておきます。
アプリケーション構成例 最小構成の Sinatra アプリケーションを Docker 上で動かすためのファイル例を Gist に上げました。
https://gist.github.com/dtan4/373907a001f3f3ebbd9c
はじめに言っておくと、Ruby のバージョンを変えること（2.1.5 にするとか）は解決になりませんでした。Ruby 2.2.0 のせいとかではない。
あと Docker のバージョンは （2015-01-21 最新の）1.4.1 です。
対処法1: Rack 1.5.2 を使う 一つ前のバージョンである Rack 1.5.2 であればこの問題は発生しません。Gemfile でバージョン指定しましょう。
gem &amp;quot;rack&amp;quot;, &amp;quot;~&amp;gt; 1.5.2&amp;quot; # or &amp;quot;= 1.5.2&amp;quot; 対処法2: rackup に -o 0.0.0.0 オプションをつける rackup --help より、
-o は ListenAddress を設定するためのオプションです。</description></item><item><title>peco で Docker の container ID を楽に選択する alias</title><link>http://blog-ja.dtan4.net/posts/qiita-839c85d2650e63f662b0/</link><pubDate>Mon, 20 Oct 2014 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-839c85d2650e63f662b0/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker 使っていると割りと container ID が必要になるケース多いと思います。 このとき一々 docker ps から container ID を探し出してコピペするのが面倒だったので、alias を定義しました。
alias -g P=&amp;#39;`docker ps | tail -n +2 | peco | cut -d&amp;#34; &amp;#34; -f1`&amp;#39; docker ps の結果を peco で絞り込みます。 これだと起動しているコンテナの ID しか取れないので、停止中のも取りたい場合は -a オプションを付ければよいです。
peco に渡す前に tail -n +2 を噛ませていますが、これは「頭から2行目以降を出力する（= 先頭行を飛ばして出力する）」というコマンドです。 docker ps は先頭行にフィールド名ヘッダが入るので、これを除去しています。
コンテナ停止 $ docker stop P コンテナのログを見る $ docker logs P nsenter を使ってコンテナに入る 予め nsenter を使えるようにしておき、.bashrc や .zshrc で docker-enter コマンドを定義しておく。
$ docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter OS X で boot2docker 経由の docker-enter を参考までに載せておきます。</description></item></channel></rss>