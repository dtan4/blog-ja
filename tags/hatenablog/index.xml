<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hatenablog on blog-ja.dtan4.net</title><link>https://dtan4.github.io/blog-ja/tags/hatenablog/</link><description>Recent content in hatenablog on blog-ja.dtan4.net</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><copyright>Copyright &amp;copy; 2020 dtan4 All Rights Reserved</copyright><lastBuildDate>Sun, 09 Jul 2017 17:55:41 +0900</lastBuildDate><atom:link href="https://dtan4.github.io/blog-ja/tags/hatenablog/index.xml" rel="self" type="application/rss+xml"/><item><title>ツールを作ろうと思うモチベーションと、作る流れ</title><link>https://dtan4.github.io/blog-ja/posts/2017-07-09-175541-hatenablog/</link><pubDate>Sun, 09 Jul 2017 17:55:41 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2017-07-09-175541-hatenablog/</guid><description>以下は完全に自分の独断と偏見で書いており、こうすべき！と押し付けるものでは一切ないことを明記しておきます。また、ツールって言ってるのはコマンドラインツールが主です。
モチベーション なぜツールを作ろうと思うのか
何かやるのに手数が多い オペレーションの工数が多くてそれが人間の手作業であるとき、往々にしてミスは発生する。 ヒューマンエラーを極力なくすために、自動化できるところは自動化すべきである。 操作がコード化されたら、その振る舞いに対してテストを書いて検証することもできる。
例えば Auto Scaling Group で管理された + ELB に吊るされた Elasticsearch のノード入れ替えは、以下の手順で行う必要があった（インスタンス起動時に Elasticsearch が立ち上がること + EC2 Discovery を仮定）。
退役させるノードを1台選ぶ（対象ノード） 対象ノードを ELB から外す Draining が終わって完全に外れるまで待つ (Elasticsearch 1系のみ) 対象ノードの _shutdown API を叩いて、shard が別のノードに退避するのを確認 対象ノードを Terminate ASG により新しいノードが追加、shard が配置されるのをされるのを確認 残りのノードに対して 1. から繰り返す これを手作業でやると、
リクエストを受け付けているのに、ELB から外さずクラスタから外してしまう or Terminate して 503 を返す 複数台一気に Terminate してしまって shard が複製ごと吹っ飛ぶ ような事故が起こりえる。
AWS も Elasticsearch も API が提供されているので、構築から状態確認まですべてプログラマブルに行える。 こういうのはワンコマンドで完結するよう自動化すべきである。
なお、上記の Elasticsearch ノード入換を自動化するツールは esnctl である。</description></item><item><title>ghrls: GitHub Tags / Releases を手元からシュッと確認するツールを作った</title><link>https://dtan4.github.io/blog-ja/posts/2017-02-13-225120-hatenablog/</link><pubDate>Mon, 13 Feb 2017 22:51:20 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2017-02-13-225120-hatenablog/</guid><description>GitHub に push されたタグの一覧、またタグに紐付いた Releases の情報をワンコマンドでシュッと表示するツール ghrls を作りました。
https://github.com/dtan4/ghrls
背景 自分は何かアプリケーション・ライブラリを作るときに依存ライブラリのバージョンを細かく気にする質で、たいてい Semantic Versioning でいう patch version レベルで指定しています (e.g. ~&amp;gt; 1.6.10, ~1.6.10)。 そういうわけで新しい依存を加えるときはまず最新バージョンがいくつか確認しているのですが、そのために毎回
該当リポジトリをブラウザで開く コミット数と並んでいる 30 Releases をクリックして開く 先頭に記載されたバージョン番号を確認する というステップを踏んでいて、さすがに面倒になっていました。
Releases に上がっている tarball の URL を確認するには、さらに「タグをクリックして開く」「tarball を右クリックで &amp;ldquo;Copy Link Address&amp;rdquo;」が加わりやってられない。
というわけで面倒くさいが高じた結果、手元でサクッと確認したいということになり ghrls を作りました。
使い方 ghrls list &amp;lt;user/name&amp;gt; で、そのリポジトリの Tag / Release 一覧を表示します。
$ ghrls list kubernetes/kubernetes | head TAG TYPE CREATEDAT NAME v1.6.0-alpha.0 TAG v1.5.3-beta.0 TAG v1.5.2 TAG+RELEASE 2017-01-12 13:51:15 +0900 JST v1.</description></item><item><title>Basic 認証かけるだけのプロキシサーバ Docker image 作った</title><link>https://dtan4.github.io/blog-ja/posts/2017-02-10-005335-hatenablog/</link><pubDate>Fri, 10 Feb 2017 00:53:35 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2017-02-10-005335-hatenablog/</guid><description>Web アプリがあってとりあえず Basic 認証かけたいときは前段に Nginx 置けば楽なんだけど、毎回設定ファイル書いたり htpasswd 生成するのが面倒なので、サクッと用意できるよう Docker image を用意しました。
https://github.com/dtan4/nginx-basic-auth-proxy
https://quay.io/repository/dtan4/nginx-basic-auth-proxy
以下のように、環境変数で username, password そしてプロキシ先の URL を指定すれば Basic 認証設定済みの Nginx が起動します。
$ docker run \ --rm \ --name nginx-basic-auth-proxy \ -p 8080:80 \ -e BASIC_AUTH_USERNAME=username \ -e BASIC_AUTH_PASSWORD=password \ -e PROXY_PASS=https://www.google.com \ -e SERVER_NAME=proxy.dtan4.net \ quay.io/dtan4/nginx-basic-auth-proxy Docker Compose や Kubernetes を使って、メインの Web アプリコンテナは外部にポートを公開しない設定で立てた上でその前段に立ててあげるとセキュアで便利かもしれません。
version: &amp;#39;2&amp;#39; services: web: image: tutum/hello-world:latest nginx: image: quay.</description></item><item><title>k8stail: Kubernetes の複数 Pod のログをまとめて流し読みできるツールを作った</title><link>https://dtan4.github.io/blog-ja/posts/2016-11-18-221429-hatenablog/</link><pubDate>Fri, 18 Nov 2016 22:14:29 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2016-11-18-221429-hatenablog/</guid><description>Kubernetes の特定の namespace にある、全 Pod のログを一括で流し読みできるコマンドラインツール k8stail を作りました。
https://github.com/dtan4/k8stail
取り急ぎこちらスクリーンショットです。
インストール Mac をお使いなら Homebrew でインストールできます。
$ brew tap dtan4/dtan4 $ brew install k8stail その他の OS 用バイナリは GitHub Releases で配布しています。
また、対応している Kubernetes のバージョンは 1.3 以上 です。
使い方 -namespace で namespace を指定すると、その namespace に所属する全ての Podのログが tail -f の如くリアルタイムで流れます。 -namespace 指定しなかったら default namespace を使います。
1 Pod に複数のコンテナがぶら下がっている場合は、それらもまとめて表示します。 コマンド実行後に Pod が追加された / 作り直されても、それに追従して新しい Pod のログが流れます。
Ctrl-C で止まります。
$ k8stail -namespace awesome-app Namespace: awesome-app Labels: ---------- Pod awesome-app-web-4212725599-67vd4 has detected Pod awesome-app-web-4212725599-6pduy has detected Pod awesome-app-web-4212725599-lbuny has detected Pod awesome-app-web-4212725599-mh3g1 has detected Pod awesome-app-web-4212725599-pvjsm has detected [awesome-app-web-4212725599-mh3g1][web] | creating base compositions.</description></item><item><title>s3url: S3 の署名付き URL を一発で発行するコマンドを作った</title><link>https://dtan4.github.io/blog-ja/posts/2016-10-22-231850-hatenablog/</link><pubDate>Sat, 22 Oct 2016 23:18:50 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2016-10-22-231850-hatenablog/</guid><description>S3 オブジェクトの署名付き URL を一発で発行できるコマンドラインツール s3url を作ったのでご紹介です。
https://github.com/dtan4/s3url
下のような感じで、S3 オブジェクトのパスを与えると5分間誰でもアクセスできる URL が即座に発行されるコマンドです。
$ s3url s3://my-bucket/foo.key https://my-bucket.s3-ap-northeast-1.amazonaws.com/foo.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIA***************************%2Fap-northeast-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20160923T010227Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=**************************************************************** S3 署名付き URL とは、指定したオブジェクトに対する「一定期間有効な」「誰でもダウンロード可能となる」URL のことです。詳しくはドキュメントを御覧ください。
http://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/ShareObjectPreSignedURL.html
インストール Mac ユーザであれば Homebrew 経由でインストール可能です。dtan4/dtan4 tap にレシピがあります。
$ brew tap dtan4/dtan4 $ brew install s3url その他の OS をお使いの方は、GitHub Releases からバイナリをダウンロードしてください。
使い方 引数に S3 オブジェクトの URL を与えることで、一時的に誰でもそのオブジェクトをダウンロード可能になる署名付き URL が表示されます。デフォルトだと5分間有効となっています。5分過ぎるとアクセスできなくなります。
$ s3url s3://my-bucket/foo.key https://my-bucket.s3-ap-northeast-1.amazonaws.com/foo.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIA***************************%2Fap-northeast-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20160923T010227Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=**************************************************************** オブジェクトのは https:// か s3:// で始まる URL、または -b, -k オプションでそれぞれ指定することができます。
-d オプションを与えることで、秒単位で有効期間を指定することができます。
# 10分間有効 $ s3url s3://my-bucket/foo.key -d 600 --upload オプションでローカルファイルのパスを指定すれば、そのファイルを S3 へアップロードした後に URL を発行します。自分のマシンにあるファイルを他人へ渡すような場合に、アップロードを他の手段でしなくてよくなるので便利です。</description></item><item><title>terraform import と Terraforming</title><link>https://dtan4.github.io/blog-ja/posts/2016-08-18-010652-hatenablog/</link><pubDate>Thu, 18 Aug 2016 01:06:52 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2016-08-18-010652-hatenablog/</guid><description>先日 Terraform 0.7 がリリースされました。 Terraform 0.7 の目玉機能は、なんと言っても既存リソースの import terraform import ではないでしょうか。全世界の Terraform ユーザが長年待ちわびていた機能がついに搭載されたことになります。 あ、あと terraform.tfstate のバージョンが 1 から 3 に上がったので後方互換性が地味に失われているのも大きいですね…
さて、自分は1年以上前から既存リソースをコード化する手段として Terraforming を開発し今に至るまでメンテナンスしてきました。
https://github.com/dtan4/terraforming
現在ではそれなりの認知をいただき、リソース追加などで Pull Request も多くもらうようになりました。 そんなことをしていたので、既存リソース import の公式対応には注目している、むしろしなければならないような立ち位置となっています。
本記事では、terraform import を試しつつ Terraforming がこの先生きのこれるのかどうかを見ていきたいと思います。
terraform import 概要 terraform import は、既存のリソースを Terraform の管理下に置くための機能です。Terraform 0.7 時点では、tfstate（Terraform がリソース管理状態を把握する JSON）のみ生成できます。人間が書く tf ファイルの生成はできません。
公式ドキュメントはこれ =&amp;gt; Import - Terraform by HashiCorp
This is a great way to slowly transition infrastructure to Terraform
とのことです。楽しみですね。</description></item><item><title>YAPC::Asia Hachioji 2016 で自作 PaaS について喋ってきた #yapc8oji</title><link>https://dtan4.github.io/blog-ja/posts/2016-07-04-230947-hatenablog/</link><pubDate>Mon, 04 Jul 2016 23:09:47 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2016-07-04-230947-hatenablog/</guid><description>というわけで、7/2-3 に開催された YAPC::Asia Hachioji 2016 に参加してきました。ついでに喋ってきました。
http://yapcasia8oji-2016mid.hachiojipm.org/
行ってきた YAPC は2013年から数えて4回目なのですが、毎回ワイワイとお祭り感があるのが参加していて楽しいです。 ワイワイしつつ、内容も面白い &amp;amp; 興味深い発表が多いですね。
SideCI の方の発表で、Terraforming 紹介してもらえてありがたかったです。 近いうちに Terraforming リポジトリへ SideCI 導入します。 あとマイクロソフトの DC の話が面白かったです。Cognitive Services とかも含めて、Azure 色々できるんだなーとか。
喋ってきた 仕事でやったネタをどっかで喋っておきたかった &amp;amp; 隣の席の先輩が応募していたので、自分も締め切り1分前に応募しました。そしたら無事採択され、今回登壇したという形です。非 LT でのちゃんとした？登壇は初めてですね。
仕事で PaaS を作ったので、それについて話しました。
https://speakerdeck.com/dtan4/number-yapc8oji
応募時にヒヨって15分枠で出してそのまま通ったわけですが、いざ資料を作ってみると15分に収まらなかったですね…発表ではデモ含めてギリギリだったのですが。 発表時間、仮に余ったらデモするなり余談するなりで埋める術はありますが短い場合だと削るしかなくて厳しいです。今後の教訓になりました。 あと、先輩が「Kubernetes 導入しました」と発表した1時間後に「自作 PaaS 導入した。ECS 入れたい」って発表するのはクレイジーでしたね…
Hosting Paus できたらいいですね〜
Paus 一応発表した Paus について簡単に紹介しときます。
https://github.com/dtan4/paus
Paus は、docker-compose.yml 書いて git push したらそれだけで Web アプリがデプロイできるというシンプルな PaaS です。とりあえす下のデモ動画で雰囲気を掴んでください:
Heroku とか OSS PaaS は便利だけど Buildpack + Addons 構成に縛られちゃう、もっと気軽にデプロイしたい。そういった流れで作りました。 全体的に荒削りですが、なんとか一通りのことはできるようになってます。</description></item><item><title>Kubernetes Meetup Tokyo #2 で LT してきた #k8sjp</title><link>https://dtan4.github.io/blog-ja/posts/2016-06-21-003142-hatenablog/</link><pubDate>Tue, 21 Jun 2016 00:31:42 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2016-06-21-003142-hatenablog/</guid><description>最近ちょくちょく人前出るようになったので、ちゃんと記録はしておこうと思いました。
六本木ヒルズの Google で開催された Kubernetes Meetup Tokyo #2 で LT してきました。
http://k8sjp.connpass.com/event/33508/
最近作った Kubernetes Secret を手軽に扱えるツール k8sec と Go Kubernetes API Client Library を使ったコードの書き方を紹介しました。準備不足感が否めなくて申し訳なかったです…。スライドはこれです。
https://speakerdeck.com/dtan4/writing-kubenetes-tools-in-go
(R, G, B) = (50, 109, 230) が Kubernetes の色っぽいです。
伝えたかったこととしては、
Ops だけでなく Dev が叩けるようなインターフェイスにしたい シェルスクリプトや書捨てスクリプトで運用するよりは、ちゃんとツールを作ったほうがいい API Client Library 使えば、ツール作るのもそう難しくはない です。
で、こいつが発表中に紹介した k8sec です。Heroku 使ってた人にとっては馴染みやすいと思うのですがどうなんでしょう…。
https://github.com/dtan4/k8sec
Kubernetes の運用は自分たちも検証段階ですが、各社それぞれ違った知見を持ちつつ同じような悩みを抱えてたりしているようでした。今回みたいな Meetup や Slack などで情報交換していけるとよさそうです。ありがとうございました。
(This post was imported from https://dtan4.hatenablog.com/entry/2016/06/21/003142)</description></item><item><title>「クラウド開発徹底攻略」を読んだ</title><link>https://dtan4.github.io/blog-ja/posts/2016-05-17-021835-hatenablog/</link><pubDate>Tue, 17 May 2016 02:18:35 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2016-05-17-021835-hatenablog/</guid><description>技術評論社さんのクラウド開発徹底攻略 (WEB+DB PRESS plus) を、特集「Docker 実戦投入」を執筆された @spesnova さんよりご恵贈いただきました。ありがとうございます。
おなじみ徹底攻略シリーズということで過去に WEB+DB Press 誌に掲載された記事を再編集したものなんですが、再掲載までおよそ1年分のアップデートが各記事にしっかりと反映されているようでした。クラウドや Docker 界隈は移り変わりが激しいので、最新情報をまとめて書籍でおさらいできるのは非常にありがたいです。
記事は「AWS 自動化」「Docker 実戦投入」といった一歩進んだ実運用の話のほか、Google Cloud Platform と Heroku の入門や BigQuery, Amazon SNS の活用まで、今時のクラウドインフラのトピックが幅広く抑えられています。Docker とか BigQuery とかってよく聞くしググれば情報は出てくるけど、じゃあベストプラクティスは？と言われると見つけにくいところがあります。そういった点で本書は一通りのプラクティスがまとまっており、おすすめです。実際の運用例だけでなく、サービスの哲学や大本の仕組みについて解説されている点も良かったです。
特に Docker 界隈は Kubernetes がメジャーになり、ベストプラクティスがここ1年で大きく移り変わってきた感じがあります。本書の「Docker 実戦投入」はその進化に追従し、全体的に、特に後半の運用話が大幅にアップデートされています。元記事ではオーケストレーションに Capistrano を使っていましたが、本書では全面的に Kubernetes を使うようになっています。そういや当時は Docker Swarm や Kubernetes がベータで、実運用投入するならどれがいいのかと悩んでましたね…。Rails アプリの運用を題材に一通りの操作が抑えてあるので、今時の Docker 事情を知りたい方や Kubernetes 導入を考えている方は参考になると思います。
というわけで、今時のクラウドインフラ事情を掴んでおきたい方、いまはオーソドックスに AWS や Docker を使っているけど一歩進んだ使い方を知りたい方はマストバイな一冊です。 自分も AWS 自動化で触れられているツールや GCP はこれまであまり触ってなかったので、これを期におさらいしておきたいです。
(This post was imported from https://dtan4.hatenablog.com/entry/2016/05/17/021835)</description></item><item><title>最近書いた Datadog にメトリクスを送りつけるツール</title><link>https://dtan4.github.io/blog-ja/posts/2015-10-18-181932-hatenablog/</link><pubDate>Sun, 18 Oct 2015 18:19:32 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2015-10-18-181932-hatenablog/</guid><description>日頃インフラメトリクスの監視には Datadog を使っています。最近せっかくなのでインフラ以外の色々も Datadog で監視したくなったので、メトリクス中継用のツールを2個ほど作りました。せっかくなので紹介します。
SendGrid2Datadog (SendGrid events) https://github.com/dtan4/sendgrid2datadog
メール配信サービスである SendGrid のイベントを Datadog 上で監視できるようにするやつです。
いまどのくらいメールが送られているかというのをパッと確認できるようにしたいと思い作りました。インフラメトリクスが置いてあるダッシュボードにこのグラフを同居させてあるため、DB 負荷が上がった時にも効率よく確認することができます。
SendGrid2Datadog 自体は Heroku 上で動作しています。
実装 SendGrid2Datadog は小さな Web アプリケーション (Ruby + Sinatra) として実装されてます。SendGrid にはメール送信や送信失敗のイベントごとに Webhook を投げる機能があるため、それを受けて都度 Datadog にイベント発生を送信するようにしています。 Datadog への送信は Dogstatsd を使っています。
Spotdog (EC2 Spot Instance History) https://github.com/dtan4/spotdog
AWS EC2 には価格変動型のスポットインスタンスというのがあります。このスポットインスタンスの価格推移を Datadog 上で監視できるようにするやつです。
この価格推移グラフ、一応 Management Console にログインすれば見れるのですがまあ面倒です。複数インスタンスタイプの一覧表示とかできません。
なので、Datadog 上で見られるように、自分の好きなようにグラフを組めるように Spotdog を作りました。上の図にあるようにオンデマンド価格を閾値として表示できるため便利です。オンデマンド価格を超えたらアラート飛ばすとかももちろん可能です。
惜しいのは、値が小数点第二位までしか表示できないことでしょうか（グラフ上は反映されてる）。c4.xlarge あたりだと小数点第三位での動きが多いのでそのへん確認できないのはつらいです。まあグラフでだいたいの推移を確認できるのでよいでしょうか。
Spotdog も Heroku 上で動作しています。ただ、こいつは後述するようにコマンドラインツールなので Heroku Scheduler で10分おきに叩くようにしています。
実装 Spotdog は Ruby なコマンドラインツールです。Docker image もあります (quay.</description></item><item><title>Terraforming: 既存のインフラリソースを Terraform コードに落としこむ</title><link>https://dtan4.github.io/blog-ja/posts/2015-06-20-181559-hatenablog/</link><pubDate>Sat, 20 Jun 2015 18:15:59 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2015-06-20-181559-hatenablog/</guid><description>インフラ界隈のみなさま、 Terraform 使ってますか？ 導入したいけど、既存のリソースの管理をどうするか悩んでないですか？
少し前からこの問題を解決する Terraforming というツールを作っていて、今回 v0.1.0 を公開したので紹介します :tada:
https://github.com/dtan4/terraforming
https://rubygems.org/gems/terraforming
これはなに Vagrant で有名な HashiCorp が開発している Terraform というインフラをコードで管理するためのツールがあります。 Infrastructure as Code というやつです。 Terraforming は、AWS の API を叩いていま動いている既存の AWS リソースから Terraform のコードを生成するツールです。
インストール RubyGems として公開されているので、
$ gem install terraforming Docker Image も用意しているので、そちらを使いたい方は
$ docker pull quay.io/dtan4/terraforming:latest 使い方 予め AWS のクレデンシャルを環境変数に入れておきます。 Mac ユーザなら envchain おすすめです。
export AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXXXXXXXX export AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx export AWS_DEFAULT_REGION=xx-yyyy-0 リソース名を指定するだけだと、tf 形式で出力されます。 S3 bucket の場合だと:
$ terraforming s3 resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;hoge&amp;#34; { bucket = &amp;#34;hoge&amp;#34; acl = &amp;#34;private&amp;#34; } resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;fuga&amp;#34; { bucket = &amp;#34;fuga&amp;#34; acl = &amp;#34;private&amp;#34; } これを s3.</description></item><item><title>Github の緑化を続けて半年経った</title><link>https://dtan4.github.io/blog-ja/posts/2014-11-19-234241-hatenablog/</link><pubDate>Wed, 19 Nov 2014 23:42:41 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2014-11-19-234241-hatenablog/</guid><description>5月頃から、「継続的緑化活動」と称して Github の Contribution Graph を埋めるというのを続けています。 そしてつい先日、継続日数 (Current streak) が180日、つまり半年を越えました。 めでたい。
https://github.com/dtan4上の Graph は Public Repository への Contribution だけで構成されています。 Private Reposirtory のものは抜いてます。 自分からはログアウトしなくとも Chrome とかのシークレットウィンドウで見られる。
問題点 ただ、Contribution Graph や実際の Activity を見るとわかるように
（特に8月以降）色が薄い 一日に大した活動をしていない dotfiles 系の更新とかが多い ちゃんとしたプロダクトの開発に手を付けられていない という状況です。 Graph がすべて緑で埋まるまで残り半年、上記のことを意識して継続的に緑化していきたい所存です。
実は LT していた 今さらですが、9月に行われた RubyHiroba 2014 （投稿現在、見られないけど）で継続的緑化活動について LT していました。 本当に飛び入りで、人生初の LT をしました。 資料を載せておきます。
あと、緑化活動を行う上で目を通しておくべき Github の公式ガイドラインをおいておきます。
Why are my contributions not showing up on my profile?</description></item><item><title>DeployGate@ミクシィのインターンに参加した</title><link>https://dtan4.github.io/blog-ja/posts/2014-09-18-002036-hatenablog/</link><pubDate>Thu, 18 Sep 2014 00:20:36 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2014-09-18-002036-hatenablog/</guid><description>8/1 から 9/5 までの5週間、DeployGate@ミクシィのインターンシップに参加してきました。 何をやったかとか感想とかを書いておきたいと思います。
参加の経緯 逆求人イベントに参加して、そこでミクシィ人事の方々と知り合ったのが最初のきっかけです。 自分は、最初からインターンは「1ヶ月スパンの長期で・実際に業務に関わるやつ」に参加したいと考えていましたが、その点ミクシィのインターンは自分の希望にマッチしていました((他社のインターンだと、2週間くらいインターン生だけで何か作るようワークショップ形式が多い))。
Internship2014 | 株式会社ミクシィ 学生向けエンジニアイベント
募集部署は数ありますが、その中でも DeployGate は
個人的に使っていた 開発環境の改善・開発の高速化を目標とするサービスである という点で興味を持ち、配属を希望しました。
業務 社員と同じように、チームにジョインしてサービスの開発に参加できます。 自分は期間通じてサーバサイド (Rails) の開発をしていました。 新機能の追加から既存箇所の修正・改良まで、いろいろさせて頂きました。 このへん、インターンとはいえ裁量広くさせてもらえます。
DeployGate では Github を用いた Pull Request ベースの開発が行われています。 コミュニケーションツールとしては、Slack とか Sqwiggle とかを取り入れていて楽しい感じでした。 プルリク上では、自分の書いたコードをがっつりと社員さんにレビューしてもらえました。
開発にあたっては、テストファーストを心がけていました。 自分が新たに実装する箇所は勿論ですが、既存箇所に手を加えるところでもテストが不足していたら補完した上で実装に入るようにしていました。 現状どのような仕様になっているのか確認する上でも、役に立ったとは思います。
DeployGate グループ DeployGate の開発チームはミクシィの中でも独立している感じで、すごくベンチャー感((というかスタートアップ感というのか))に溢れていました。 色々自由な雰囲気でした。
インターン中に開発した機能 色々させてもらったのですが、ここで自分が開発に携わった機能を2つほど紹介しようと思います。
Invite API で DeployGate 未登録の人を招待 DeployGate には、アプリケーション開発者に他の人を招待する Invite API というものがあります。 従来は、API 経由だとすでに DeployGate に登録しているユーザしか招待できませんでした((ブラウザからは招待できた))。
今回、この Invite API で未登録の人もメールアドレスで招待できるようにしました。 API 書式は従来と変わらず、users に未登録なメールアドレスを指定できるようになっています。</description></item><item><title>mado: Markdown をリアルタイムプレビューするツール作った</title><link>https://dtan4.github.io/blog-ja/posts/2014-06-08-220211-hatenablog/</link><pubDate>Sun, 08 Jun 2014 22:02:11 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2014-06-08-220211-hatenablog/</guid><description>Markdown のリアルタイムプレビューを行う mado というツールを作った。 世の中 Markdown Previewer なんてごまんとありそうだけど、とりあえず作った。
mado | RubyGems.org
特徴 Web ブラウザ上で Markdown をプレビュー Markdown を HTML 整形したものを Web ブラウザ上でプレビューできる。 Github Flavored Markdown に対応している。 好きなエディタで編集しつつ、横にブラウザを開いてどんな出力になるかを確認しながら使う感じ。
また、プレビューの見た目は Github 上での Markdown プレビューになるべく似せるようにしている。 Github に上げるプロジェクトの README.md を編集するのに便利ではないだろうか。
ちなみに、Github ライクな見た目の実現には github.css に手を加えたものを使用している。
Markdown ファイルの変更を検知して、プレビューをリアルタイムに更新 Markdown ファイルを編集すると、WebSocket を通じてプレビューがリアルタイムに更新される。 リロードする必要はない。
シンタックスハイライト fenced code-block (バッククォート3つで囲むやつ) に書いたコードはシンタックスハイライトされる。 ハイライトの色は Github 上での色に準じている。
相対パス画像展開 ローカル上にある画像を相対パス指定で表示することができる。
![local image](img/hoge.png) スクリーンショット インストール gem として提供している。
$ gem install mado 起動 mado はコマンドラインツールである。 編集したい Markdown ファイルを指定して起動する。</description></item><item><title>人生初の Pull Request を出した</title><link>https://dtan4.github.io/blog-ja/posts/2014-05-13-210438-hatenablog/</link><pubDate>Tue, 13 May 2014 21:04:38 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2014-05-13-210438-hatenablog/</guid><description>昨晩、GitLab (gitlabhq/gitlabhq) のドキュメントにデッドリンクを見つけたので、人生初の Pull Request を出した。
Fix dead links in ruby.md by dtan4 · Pull Request #6959 · gitlabhq/gitlabhq
最初は絶対パス指定の修正をしていたけど、相対パスのほうが好ましいですね〜というアドバイスをもらって追加コミットしたりした。 たぶん初めて squash と push -f を使った。
そして今日マージしていただけたので、めでたく one of the GitLab contributors になった。
こういう感じで OSS への貢献を増やしていきたい。
(This post was imported from https://dtan4.hatenablog.com/entry/2014/05/13/210438)</description></item><item><title>Markdown を Pukiwiki 記法に変換する gem 作った</title><link>https://dtan4.github.io/blog-ja/posts/2014-04-30-235331-hatenablog/</link><pubDate>Wed, 30 Apr 2014 23:53:31 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2014-04-30-235331-hatenablog/</guid><description>講義の関係で、しばらく Pukiwiki 上でブログっぽいのを書き続けることになった。ただ Pukiwiki 記法を新しく覚えるのが面倒なので、普段書き慣れている Markdown で書けるように変換器を書いた。
md2pukiwiki | RubyGems.org
Install $ gem install md2pukiwiki Usage md2pukiwiki というコマンドを用意してある。
引数に Markdown ファイルを指定することで、Pukiwiki 記法に変換されたテキストが標準出力に吐かれる。リダイレクトで別ファイルに出力するか、パイプ経由で pbcopy してクリップボードにコピーしたりするのが良い。
$ md2pukiwiki sample.md Ruby コード内で変換を行うには、以下のように書く。
require &amp;#34;md2pukiwiki&amp;#34; pukiwiki = Md2Pukiwiki.convert(markdown) Example この Markdown が
# header * list1 * l**is**t2 * list2.1 ## subheader 1. nlist1 2. nl*is*t2 1. nlist2.1 こういう Pukiwiki 記法に変換される。
*header - list1 - l''is''t2 -- list2.1 **subheader + nlist1 + nl'''is'''t2 ++ nlist2.</description></item><item><title>VAIO Pro に Arch Linux をインストールする</title><link>https://dtan4.github.io/blog-ja/posts/2013-12-04-015333-hatenablog/</link><pubDate>Wed, 04 Dec 2013 01:53:33 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-12-04-015333-hatenablog/</guid><description>2014/02/20 再インストールに伴い数カ所修正
===
VAIO Pro 11 を買ったので、これまでの環境と同じく Arch Linux を入れました。（これまでは ArchBang を使っていたので）素の Arch を入れるのは初めて。
なお、以下の作業は 2013-10-28 時点のものです。現在でも大体このままで大丈夫だと思いますが、まずいところは ArchWiki など参照して適宜修正してください。
準備するもの VAIO Pro 有線ネットワーク環境 USB 有線 LAN アダプタ DVD-R 4枚（or 同等の容量分の光学メディアか USB メモリ） 光学メディアを使うなら USB 外付けドライブ リカバリメディア用 USB メモリ LiveUSB 用 Arch Linux LiveUSB を作る （Mac or Linux 上で作業していると仮定） iso イメージをダウンロード 日本におるなら jaist あたりのミラーを使うべき USB メモリを刺す すぐに sudo dmesg | tail -20 sda:sda1 とか表示されたのを覚えておく iso を USB メモリに焼く dd if=/path/to/iso of=/dev/sdX bs=1M sdX はさっき覚えたやつ Windows を処分する 万一のために、リカバリディスクを作っておく VAIO Update をかけて BIOS とか色々最新化しておく ASSIST ボタンを押すか VAIO Care (Desktop) を開く リカバリメディアの作成をする フラッシュメモリか、外付け光学ドライブ + 光学メディアが必要 DVD-R 4.</description></item><item><title>nowtv: 現在放送中の番組一覧を確認するコマンド作った</title><link>https://dtan4.github.io/blog-ja/posts/2013-10-02-195528-hatenablog/</link><pubDate>Wed, 02 Oct 2013 19:55:28 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-10-02-195528-hatenablog/</guid><description>2015-01-24 22:00 追記 利用させてもらっていた API が廃止されたようで、nowtv は現在データを取得できず使用することができません。 とりあえず gem の公開と Github でのソースの公開、そして本記事の公開は続けておきますが、コマンド自体は何もできないことをご留意ください。
以下は nowtv 公開時点での記事です。
現在放送中の番組を確認できるコマンドラインツール nowtv を作った。ご利用ください。
背景 今テレビで何放送しているかな、というのを確認するのに一々ブラウザ立ちあげて番組表サイトにアクセスするのが面倒だった。コンソール上でサクッと確認したかったので作ってみた。
インストール RubyGems で配布しているので gem install nowtv
使い方 nowtv を呼ぶと、現在放送しているテレビ番組一覧を表示する。デフォルトでは東京都の番組表。
$ nowtv NHK総合: 仕事ハッケン伝 [16:05 -&amp;gt; 16:55] NHK Eテレ: 第68回国民体育大会～スポーツ祭東京2013～ [16:00 -&amp;gt; 17:00] 日本テレビ: 特選ぶらり途中下車の旅 [15:55 -&amp;gt; 16:53] テレビ朝日: 相棒セレクション [15:57 -&amp;gt; 16:53] TBSテレビ: Nスタ [15:50 -&amp;gt; 19:00] テレビ東京: L4YOU! [16:00 -&amp;gt; 16:52] フジテレビ: 踊る大捜査線 [15:50 -&amp;gt; 16:50] TOKYO MX: スマイルプリキュア!</description></item><item><title>東京アメッシュをコマンドラインから利用できるツール ramesh を作った</title><link>https://dtan4.github.io/blog-ja/posts/2013-07-15-212850-hatenablog/</link><pubDate>Mon, 15 Jul 2013 21:28:50 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-07-15-212850-hatenablog/</guid><description>昨日は多摩の方まで走りに行ったら、帰りがけにゲリラ豪雨にあってしまった。尾根幹の陸橋下で30分くらい雨宿りしとった。
東京都下水道局が提供する東京アメッシュという素晴らしいサービスが有る。現在から2時間前までの5分間隔で、南関東一帯の降水量を確認することができる。特に都内の観測範囲は緻密。ゲリラ豪雨が発生するとその地点が局地的に赤くなるので、「ゲリラ豪雨が近づいてきそうだ」という予測を立てるのも容易。
で、この素晴らしきサービスをコマンドラインから利用できるツール ramesh を作った。アメッシュ確認するのに一々ブラウザ開きたくない人ご利用ください。
なにこれ 東京アメッシュが提供している降水量レーダー画像をダウンロードするツール。現在の画像はもちろん、過去に遡っての画像取得も可能。
インストール ImageMagick が必要。画像合成処理をしているので。
ramesh は gem として公開しているので普通に
$ gem install ramesh でインストールできる。
つかいかた 引数を指定しないと、現在のレーダー画像をダウンロードする。
$ ramesh 過去の画像を取得することもできる。分は0-120の間、5分単位で指定する必要がある。以下の例だと90分前の画像をダウンロードする。
$ ramesh 90 範囲を指定して、複数枚の画像を取得することもできる。以下の例だと50分前から120分前まで5分間隔で、合計15枚の画像をダウンロードする。
$ ramesh 50-120 ソースコード github - dtan4/ramesh
技術情報 ブラウザに表示されるアメッシュのレーダー画像は、3枚の画像が重なりあったものである。上から順に、
都県名・都県境の画像 /map/msk000.png 降水量メッシュ画像 /mesh/000/yyyyMMddhhmm.gif 地形図 /map/map000.png このうち、上2つは背景透過がなされているので、重ねるといい具合に表示できる。ramesh は3枚それぞれをダウンロードしてきて、それらを合成したものを1枚の gif として保存している。
また、現在アメッシュのサーバに保存されているメッシュ画像の一覧は以下の JavaScript ファイルに書いてある。これをパースすれば画像ファイル名をとれる。
http://tokyo-ame.jwa.or.jp/scripts/mesh_index.js
余談 今は自宅鯖で ramesh を cron で回してデータ蓄積しとる。10日間で3300枚、770MB 超。時折溜めた分引っ張ってきてパラパラ漫画見たくアニメーション作ったりしとる。
初めての gem なので、先人の書いた gem を色々参考にしながら書いてみた。とりあえず大体の流れはつかめた感じ。
(This post was imported from https://dtan4.</description></item><item><title>GPS データ (GPX) から移動距離を求める</title><link>https://dtan4.github.io/blog-ja/posts/2013-06-10-013724-hatenablog/</link><pubDate>Mon, 10 Jun 2013 01:37:24 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-06-10-013724-hatenablog/</guid><description>GPS データから走行距離を計算したくて、緯度経度を用いた距離計算法を調べてみた。そしてスクリプト書いた。
2点間距離を求める 緯度経度を用いて距離を測定するには、ヒュベニの公式を使うのがわりとポピュラーそうだった。この式は、3D地図ソフトのカシミール3Dで使われていたりする。
カシミール / 計算式に載っている式を転載すると、
D=sqrt((M*dP)*(M*dP)+(N*cos(P)*dR)*(N*cos(P)*dR)) D: ２点間の距離(m) P: ２点の平均緯度 dP: ２点の緯度差 dR: ２点の経度差 M: 子午線曲率半径 N: 卯酉線曲率半径 M=6334834/sqrt((1-0.006674*sin(P)*sin(P))^3) N=6377397/sqrt(1-0.006674*sin(P)*sin(P)) こんな感じ。
もう少し詳しい解説はこのページにのってる。今回はここを参考にした。
二地点の緯度・経度からその距離を計算する（日本は山だらけ〜）
基本上ページ Fig.1 の通りにプログラムを書けばいいけど、ヒュベニの公式で用いる緯度経度はラジアンであるのに注意しなければならない（ハマった）。GPS で記録される緯度経度は勿論度なので変換する必要がある。
# deg（度）から rad（ラジアン）を求める rad = deg * Math::PI / 180 高校数学を思い出す。
あと、子午線曲率半径の算出に長半径（赤道半径）・卯酉線曲率半径を求めるのに短半径（極半径）が必要だけど、今回は GPS に使われるらしい WGS84 基準のパラメータを用いた。
測定誤差 地球は楕円体だしということで、やっぱり計算結果に誤差は出てくる。下のページで検証がなされている。
緯度経度から2点間の距離を求める | ぷちのいず
上のページによると、ヒュベニの公式を用いた場合は50km以上から誤差が大きくなるらしい。今回は自転車の走行距離を（主に）算出したいので、結果は高々200kmといったところ。まあ問題ないということにした。
GPX ファイルから移動距離を計算する 以上の計算を、GPX ファイル（GPS データを格納する XML）に記録されたトラックポイント間に対して行う。
GPX ファイルの中身は XML になっている。構造の説明は置いといて、トラックポイントの緯度経度は trkpt タグに属性値として記録されている。こんな感じ。
&amp;lt;trkpt lat=&amp;#34;35.765263255&amp;#34; lon=&amp;#34;139.867893811&amp;#34;&amp;gt; こっから lat （緯度）と lng （経度）を正規表現抽出して配列に格納。全部抽出し終わったら先頭から各要素間の距離を求めていく。ラジアン変換も忘れずに。その総和が移動距離になる。</description></item><item><title>rbenv でインストールした Ruby を Emacs で使う</title><link>https://dtan4.github.io/blog-ja/posts/2013-04-08-133458-hatenablog/</link><pubDate>Mon, 08 Apr 2013 13:34:58 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-04-08-133458-hatenablog/</guid><description>Mac では rbenv でインストールした Ruby 2.0.0p0 を使っとるけど、Emacs の smart-compile が呼ぶ Ruby は /usr/bin/ruby つまり Ruby 1.8.7 で不便やった。
rbenv の Ruby を使うには 、Emacs の環境変数 PATH に rbenv のパス（ターミナルで which ruby してでるやつ）を追加すれば良い。 .emacs なり init.el なりに以下を記述する。
(setenv &amp;#34;PATH&amp;#34; (concat (expand-file-name &amp;#34;~/.rbenv/shims:&amp;#34;) (getenv &amp;#34;PATH&amp;#34;))) 参考 http://d.hatena.ne.jp/gan2/20120528/1338191267
(This post was imported from https://dtan4.hatenablog.com/entry/2013/04/08/133458)</description></item><item><title>uim-mozc 周りのインストールで躓いた</title><link>https://dtan4.github.io/blog-ja/posts/2013-03-28-023536-hatenablog/</link><pubDate>Thu, 28 Mar 2013 02:35:36 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-03-28-023536-hatenablog/</guid><description>Arch Linux での日本語入力には uim-mozc を常用。 さっき久々に yaourt -Syu して再起動したら日本語入力できやんくなっとった。 とりあえず uim-mozc と uim を再インストールしてみることにした。
uimの再インストールは問題なかったけど、yaourt -S uim-mozc で uim-mozc をインストールし直そうとしたら、ビルド段階で
&amp;ldquo;/etc/profile.d/qt4.sh&amp;rdquo; が見つかりません
みたいなこと言われた。 別の AUR パッケージのコメントによると、最新バージョン (qt4 4.8.4-16) では qt4.sh が廃止されたらしい（上から2つめのコメント）。
PKGBUILD を編集したら何とかなりそうやけど、よくわからんのでネットから qt4.sh を落としてきた。&amp;ldquo;qt4.sh&amp;rdquo; でググった一発目のをそのまま /etc/profile.d/ に突っ込めばOK。slackware やけどキニシナイ。↓
http://mirrors.slackware.com/slackware/slackware_source/l/qt/profile.d/qt4.sh
これでビルドが通る、はず。
はず、というのも上のやり取りの中で mozc-ut モジュールの存在を知ったので、最後はそっちで入れた。
yaourt -S mozc-utで、PKGBUILD の _uim-mozc= 行をコメントアウトする。 終わったら画面の指示通り sudo uim-module-manager --register mozc して再起動すれば日本語入力できるようになる。 Input Japanese using uim (日本語) - ArchWiki 参照
ArchWiki はやはり痒いところに手が届く。</description></item><item><title>2ch を JSON に変換するサーバ作った</title><link>https://dtan4.github.io/blog-ja/posts/2013-03-14-143725-hatenablog/</link><pubDate>Thu, 14 Mar 2013 14:37:25 +0900</pubDate><guid>https://dtan4.github.io/blog-ja/posts/2013-03-14-143725-hatenablog/</guid><description>2ch のデータをパースして JSON に変換する API サーバ 2son を作った。 http://twoson.herokuapp.com/
Heroku 便利
できること 以下のデータを JSON に変換できる 板一覧 (bbstable) スレッド一覧 (subject) スレッド (thread) dat 落ちスレッドにも対応 コールバック関数を指定すれば、JSONP を取得することもできる。 仕様 トップページで API の呼び方、返ってきた JSON の書式を説明してある。 http://twoson.herokuapp.com/
いろいろ Ruby 1.9.3 で開発。Ruby の勉強がてら組んでみた。
データ取得 ブラウザで表示する形式、つまり read.cgi を通してスレッドを取得するのはサーバーに負荷がかかるし、またパースするもの面倒やからよろしくない。したがって、データが欲しい時場合スレッド一覧は subject.txt、スレッドは dat ファイルを直接読みに行くのが推奨される。これらのファイルは1行1（スレッド | レス）で、デリミタは &amp;lt;&amp;gt; になっとってパースもしやすい。このへんは開発資料で詳しく解説してある。
また、通信量低減のためにレスポンスは gzip でもらう。リクエストヘッダに
&amp;quot;Accept-Encoding&amp;quot;: &amp;quot;gzip&amp;quot; を付与する。もちろんもらった後は解凍処理が必要。
あと、データのエンコーディングは Shift-JIS やから nkf で UTF-8 に変えると良い。必要なら。</description></item></channel></rss>