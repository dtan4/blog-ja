<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on blog-ja.dtan4.net</title><link>http://blog-ja.dtan4.net/posts/</link><description>Recent content in Posts on blog-ja.dtan4.net</description><generator>Hugo -- gohugo.io</generator><language>ja-JP</language><copyright>Copyright &amp;copy; 2020 dtan4 All Rights Reserved</copyright><lastBuildDate>Mon, 18 Dec 2017 00:00:00 +0000</lastBuildDate><atom:link href="http://blog-ja.dtan4.net/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>全ての Pod を一発でリロードさせる方法</title><link>http://blog-ja.dtan4.net/posts/qiita-9e0ab5dbe8c64ed6dd21/</link><pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-9e0ab5dbe8c64ed6dd21/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
前提条件:
Deployment を使ってアプリケーションのデプロイ管理を行っている tl;dr PodTemplateSpec の Label か Annotation (.spec.template.metadata.[labels|annotations]) に適当な key-value を追加・上書きする。 value はタイムスタンプにでもしておくと便利。
apiVersion: extensions/v1beta1 kind: Deployment metadata: name: awesome-app labels: name: awesome-app role: web spec: minReadySeconds: 30 strategy: type: RollingUpdate rollingUpdate: maxSurge: 50% maxUnavailable: 0 replicas: 20 template: metadata: name: awesome-app labels: name: awesome-app role: web annotations: reloaded-at: &amp;#34;20171217190756&amp;#34; # &amp;lt;========== これ シェルコマンド一発でやるなら以下。エイリアス作っておくと便利。
# &amp;#34;frontend&amp;#34; Deployment 配下の Pod を全部リロードする $ kubectl patch deployment frontend -p \ &amp;#34;{\&amp;#34;spec\&amp;#34;:{\&amp;#34;template\&amp;#34;:{\&amp;#34;metadata\&amp;#34;:{\&amp;#34;annotations\&amp;#34;:{\&amp;#34;reloaded-at\&amp;#34;:\&amp;#34;`date +&amp;#39;%Y%m%d%H%M%S&amp;#39;`\&amp;#34;}}}}}&amp;#34; Why Kubernetes で Pod に設定を注入するには ConfigMap や Secret が主に使われます。 これらの中身は Pod 起動時に Pod へコピーされる仕組みとなっているため、アプリケーション起動中に中身を変更してもそれが即反映されるわけではありません。 Pod を作りなおす必要があります。</description></item><item><title>ツールを作ろうと思うモチベーションと、作る流れ</title><link>http://blog-ja.dtan4.net/posts/2017-07-09-175541-hatenablog/</link><pubDate>Sun, 09 Jul 2017 17:55:41 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2017-07-09-175541-hatenablog/</guid><description>以下は完全に自分の独断と偏見で書いており、こうすべき！と押し付けるものでは一切ないことを明記しておきます。また、ツールって言ってるのはコマンドラインツールが主です。
モチベーション なぜツールを作ろうと思うのか
何かやるのに手数が多い オペレーションの工数が多くてそれが人間の手作業であるとき、往々にしてミスは発生する。 ヒューマンエラーを極力なくすために、自動化できるところは自動化すべきである。 操作がコード化されたら、その振る舞いに対してテストを書いて検証することもできる。
例えば Auto Scaling Group で管理された + ELB に吊るされた Elasticsearch のノード入れ替えは、以下の手順で行う必要があった（インスタンス起動時に Elasticsearch が立ち上がること + EC2 Discovery を仮定）。
退役させるノードを1台選ぶ（対象ノード） 対象ノードを ELB から外す Draining が終わって完全に外れるまで待つ (Elasticsearch 1系のみ) 対象ノードの _shutdown API を叩いて、shard が別のノードに退避するのを確認 対象ノードを Terminate ASG により新しいノードが追加、shard が配置されるのをされるのを確認 残りのノードに対して 1. から繰り返す これを手作業でやると、
リクエストを受け付けているのに、ELB から外さずクラスタから外してしまう or Terminate して 503 を返す 複数台一気に Terminate してしまって shard が複製ごと吹っ飛ぶ ような事故が起こりえる。
AWS も Elasticsearch も API が提供されているので、構築から状態確認まですべてプログラマブルに行える。 こういうのはワンコマンドで完結するよう自動化すべきである。
なお、上記の Elasticsearch ノード入換を自動化するツールは esnctl である。</description></item><item><title>手元の全 Ruby バージョンから特定の gem を一掃する</title><link>http://blog-ja.dtan4.net/posts/qiita-215f688a86d22c30362e/</link><pubDate>Tue, 28 Mar 2017 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-215f688a86d22c30362e/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
(2017/03/29 10:50 追記)
rbenv でインストールしたバージョン全てに対してコマンドを実行する rbenv-each というプラグインがあったので、以下のコマンドでやりたいことが実現できました。
$ rbenv each gem uninstall -x gemname rbenv-each は @sakuro さんにコメントでご教示いただきました。ありがとうございました。
$ export GEM_NAME=gemname $ for v in `rbenv whence $GEM_NAME`; do rbenv shell $v; gem uninstall -x $GEM_NAME; rbenv shell --unset; done 昔 Ruby で作ったコマンドラインツールを Go で書き換えた、けど rbenv のパスが PATH の先頭寄りに書かれていて優先されてしまう（下の例）…というときに便利です。nodenv や plenv でも、適切なコマンドに入れ替えれば応用できそう。
$ gemname rbenv: gemname: command not found The `gemname' command exists in these Ruby versions: 2.3.0 2.</description></item><item><title>ghrls: GitHub Tags / Releases を手元からシュッと確認するツールを作った</title><link>http://blog-ja.dtan4.net/posts/2017-02-13-225120-hatenablog/</link><pubDate>Mon, 13 Feb 2017 22:51:20 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2017-02-13-225120-hatenablog/</guid><description>GitHub に push されたタグの一覧、またタグに紐付いた Releases の情報をワンコマンドでシュッと表示するツール ghrls を作りました。
https://github.com/dtan4/ghrls
背景 自分は何かアプリケーション・ライブラリを作るときに依存ライブラリのバージョンを細かく気にする質で、たいてい Semantic Versioning でいう patch version レベルで指定しています (e.g. ~&amp;gt; 1.6.10, ~1.6.10)。 そういうわけで新しい依存を加えるときはまず最新バージョンがいくつか確認しているのですが、そのために毎回
該当リポジトリをブラウザで開く コミット数と並んでいる 30 Releases をクリックして開く 先頭に記載されたバージョン番号を確認する というステップを踏んでいて、さすがに面倒になっていました。
Releases に上がっている tarball の URL を確認するには、さらに「タグをクリックして開く」「tarball を右クリックで &amp;ldquo;Copy Link Address&amp;rdquo;」が加わりやってられない。
というわけで面倒くさいが高じた結果、手元でサクッと確認したいということになり ghrls を作りました。
使い方 ghrls list &amp;lt;user/name&amp;gt; で、そのリポジトリの Tag / Release 一覧を表示します。
$ ghrls list kubernetes/kubernetes | head TAG TYPE CREATEDAT NAME v1.6.0-alpha.0 TAG v1.5.3-beta.0 TAG v1.5.2 TAG+RELEASE 2017-01-12 13:51:15 +0900 JST v1.</description></item><item><title>Basic 認証かけるだけのプロキシサーバ Docker image 作った</title><link>http://blog-ja.dtan4.net/posts/2017-02-10-005335-hatenablog/</link><pubDate>Fri, 10 Feb 2017 00:53:35 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2017-02-10-005335-hatenablog/</guid><description>Web アプリがあってとりあえず Basic 認証かけたいときは前段に Nginx 置けば楽なんだけど、毎回設定ファイル書いたり htpasswd 生成するのが面倒なので、サクッと用意できるよう Docker image を用意しました。
https://github.com/dtan4/nginx-basic-auth-proxy
https://quay.io/repository/dtan4/nginx-basic-auth-proxy
以下のように、環境変数で username, password そしてプロキシ先の URL を指定すれば Basic 認証設定済みの Nginx が起動します。
$ docker run \ --rm \ --name nginx-basic-auth-proxy \ -p 8080:80 \ -e BASIC_AUTH_USERNAME=username \ -e BASIC_AUTH_PASSWORD=password \ -e PROXY_PASS=https://www.google.com \ -e SERVER_NAME=proxy.dtan4.net \ quay.io/dtan4/nginx-basic-auth-proxy Docker Compose や Kubernetes を使って、メインの Web アプリコンテナは外部にポートを公開しない設定で立てた上でその前段に立ててあげるとセキュアで便利かもしれません。
version: &amp;#39;2&amp;#39; services: web: image: tutum/hello-world:latest nginx: image: quay.</description></item><item><title>GitHub Releases にアップロードしてある最新バージョンの成果物を取得するワンライナー</title><link>http://blog-ja.dtan4.net/posts/qiita-1a9f16ff881ac456c18f/</link><pubDate>Tue, 31 Jan 2017 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-1a9f16ff881ac456c18f/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
e.g. dtan4/s3url 最新バージョンの Linux 64bit バイナリが入った tarball を取得する
$ curl -s https://api.github.com/repos/dtan4/s3url/releases | jq -r &amp;#39;.[0].assets[] | select(.name | test(&amp;#34;linux-amd64.tar.gz&amp;#34;)) | .browser_download_url&amp;#39; https://github.com/dtan4/s3url/releases/download/v0.3.1/s3url-v0.3.1-linux-amd64.tar.gz サーバに Go バイナリを配置していて定期的に更新したい場合は、このワンライナーと展開処理を行うスクリプトを cron とかで回しておけばよさそうです。
curl -s https://api.github.com/repos/dtan4/s3url/releases dtan4/s3url リポジトリの Releases を取得する GitHub API です。 Public リポジトリなら認証無しで叩けますが、その場合の呼出回数は1時間あたり最大60回となってるので、Access Token を付与するほうが安心です。
Releases | GitHub Developer Guide
jq -r -r オプションをつけると、ダブルクオートで囲まずそのまま文字列を返します。
.[0].assets[] 上記 API のレスポンスは Release 作成時刻 created_at 降順になっているので、先頭の要素が最新の Release となります。assets に成果物 (asset) のメタデータが配列で格納されてます。
select(.name | test(&amp;quot;linux-amd64.tar.gz&amp;quot;)) name フィールドが linux-amd64.</description></item><item><title>Go でツール書くときの Makefile 晒す</title><link>http://blog-ja.dtan4.net/posts/qiita-8c417b629b6b2033a541/</link><pubDate>Thu, 08 Dec 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-8c417b629b6b2033a541/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Go でツール書くときはタスクランナーとして make を使っています。ビルドだけじゃなくて、テストや配布用パッケージ作成も一括して make でやっています。 今回は整理も兼ねて、自分が普段どういう Makefile を使っているのか解剖していきます。
なぜ make を使うのか ビルドフラグ覚えるのが面倒だから、make は (Windows を除く) 大半のプラットフォームに入っていて使いやすいからというのが理由です。script/build みたいにシェルスクリプトを複数用意するのでもまあ良いと思いますが…。大半の Go プロジェクトは Makefile 置いてありますね。
make を使った開発フロー 基本的には、リポジトリを git clone / go get -d した後に以下のコマンドを打てばアプリケーションをインストールできるようにしています。
$ cd $GOPATH/src/github.com/yourname/yourapp $ make deps $ make $ make install $ yourapp 以前 make deps は余分で make &amp;amp;&amp;amp; make install で完結してほしいと言われたことがあったのですが、glide install するオーバーヘッドが（変更なくとも）多少あったので deps は入れました。Kubernetes 系とかデカいの依存してるとね… LL だと bundle install だの npm install だのを独立に行うので、まあいいのではないでしょうか。
変数定義 NAME := s3url VERSION := v0.</description></item><item><title>k8stail: Kubernetes の複数 Pod のログをまとめて流し読みできるツールを作った</title><link>http://blog-ja.dtan4.net/posts/2016-11-18-221429-hatenablog/</link><pubDate>Fri, 18 Nov 2016 22:14:29 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2016-11-18-221429-hatenablog/</guid><description>Kubernetes の特定の namespace にある、全 Pod のログを一括で流し読みできるコマンドラインツール k8stail を作りました。
https://github.com/dtan4/k8stail
取り急ぎこちらスクリーンショットです。
インストール Mac をお使いなら Homebrew でインストールできます。
$ brew tap dtan4/dtan4 $ brew install k8stail その他の OS 用バイナリは GitHub Releases で配布しています。
また、対応している Kubernetes のバージョンは 1.3 以上 です。
使い方 -namespace で namespace を指定すると、その namespace に所属する全ての Podのログが tail -f の如くリアルタイムで流れます。 -namespace 指定しなかったら default namespace を使います。
1 Pod に複数のコンテナがぶら下がっている場合は、それらもまとめて表示します。 コマンド実行後に Pod が追加された / 作り直されても、それに追従して新しい Pod のログが流れます。
Ctrl-C で止まります。
$ k8stail -namespace awesome-app Namespace: awesome-app Labels: ---------- Pod awesome-app-web-4212725599-67vd4 has detected Pod awesome-app-web-4212725599-6pduy has detected Pod awesome-app-web-4212725599-lbuny has detected Pod awesome-app-web-4212725599-mh3g1 has detected Pod awesome-app-web-4212725599-pvjsm has detected [awesome-app-web-4212725599-mh3g1][web] | creating base compositions.</description></item><item><title>s3url: S3 の署名付き URL を一発で発行するコマンドを作った</title><link>http://blog-ja.dtan4.net/posts/2016-10-22-231850-hatenablog/</link><pubDate>Sat, 22 Oct 2016 23:18:50 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2016-10-22-231850-hatenablog/</guid><description>S3 オブジェクトの署名付き URL を一発で発行できるコマンドラインツール s3url を作ったのでご紹介です。
https://github.com/dtan4/s3url
下のような感じで、S3 オブジェクトのパスを与えると5分間誰でもアクセスできる URL が即座に発行されるコマンドです。
$ s3url s3://my-bucket/foo.key https://my-bucket.s3-ap-northeast-1.amazonaws.com/foo.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIA***************************%2Fap-northeast-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20160923T010227Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=**************************************************************** S3 署名付き URL とは、指定したオブジェクトに対する「一定期間有効な」「誰でもダウンロード可能となる」URL のことです。詳しくはドキュメントを御覧ください。
http://docs.aws.amazon.com/ja_jp/AmazonS3/latest/dev/ShareObjectPreSignedURL.html
インストール Mac ユーザであれば Homebrew 経由でインストール可能です。dtan4/dtan4 tap にレシピがあります。
$ brew tap dtan4/dtan4 $ brew install s3url その他の OS をお使いの方は、GitHub Releases からバイナリをダウンロードしてください。
使い方 引数に S3 オブジェクトの URL を与えることで、一時的に誰でもそのオブジェクトをダウンロード可能になる署名付き URL が表示されます。デフォルトだと5分間有効となっています。5分過ぎるとアクセスできなくなります。
$ s3url s3://my-bucket/foo.key https://my-bucket.s3-ap-northeast-1.amazonaws.com/foo.key?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=AKIA***************************%2Fap-northeast-1%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20160923T010227Z&amp;amp;X-Amz-Expires=300&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=**************************************************************** オブジェクトのは https:// か s3:// で始まる URL、または -b, -k オプションでそれぞれ指定することができます。
-d オプションを与えることで、秒単位で有効期間を指定することができます。
# 10分間有効 $ s3url s3://my-bucket/foo.key -d 600 --upload オプションでローカルファイルのパスを指定すれば、そのファイルを S3 へアップロードした後に URL を発行します。自分のマシンにあるファイルを他人へ渡すような場合に、アップロードを他の手段でしなくてよくなるので便利です。</description></item><item><title>EC2 + IAM Role で供給されたクレデンシャルを環境変数として使う</title><link>http://blog-ja.dtan4.net/posts/qiita-4f687a74abcbe1a36190/</link><pubDate>Mon, 03 Oct 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-4f687a74abcbe1a36190/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
2016-12-09 14:15 追記 EC2 上の Docker コンテナ内からでも、AWS_ 環境変数を設定することなくインスタンスプロファイルが使えました。
AWS SDK は AWS_* 環境変数設定されてなかったら自動で http://169.254.169.254/latest/meta-data/... を叩いてクレデンシャルを取りに行きます。で、ホスト直実行でもコンテナ挟むのでもつなぎに行くネットワークは同じ AWS なので問題なくインスタンスプロファイルを取れるのでした。
したがって、この記事に書いてあるような手間をかける必要はありません…
tl;dr AWS_SECURITY_TOKEN AWS_SESSION_TOKEN を忘れるな
2019-03-11 追記 awscli は AWS_SECURITY_TOKEN で実行できますが、 AWS SDK は AWS_SESSION_TOKEN でないと動作しないものがあるようです。 ログイン画面から発行されるワンタイムパスワードも現在は AWS_SESSION_TOKEN であるため、そちらに統一する方が良さそうです。
時代は IAM Role EC2 上で AWS リソースにアクセスする場合、専用の IAM ユーザを作ってクレデンシャルを発行してもいいのですが、IAM Role を EC2 に紐付けると便利です。クレデンシャルをアプリケーションコードやスクリプトに埋め込む必要がなくなるからです。
しかし awscli や AWS SDK を埋め込んだコードを__ホスト上で直に__実行する場合は彼らがよしなにクレデンシャルを取得するのでいいのですが、Docker コンテナ上で実行する場合は少々面倒です。-e AWS_ACCESS_KEY_ID= でクレデンシャルを渡したいのですが値はどこから取ればいいのか。
※ 今回は ECS 上ではなく1、直接インスタンス上で docker run する場合の話です。
metadata からクレデンシャルを取り出す EC2 インスタンス内部から http://169.</description></item><item><title>Travis CI から複数ファイルを GitHub Releases にアップロードする</title><link>http://blog-ja.dtan4.net/posts/qiita-f2736c25c4eb63b2d206/</link><pubDate>Thu, 22 Sep 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-f2736c25c4eb63b2d206/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Travis CI から GitHub Releases にアップロードする Go などのコンパイラ言語で書いたソフトウェアを配布する場所として、最近は GitHub Releases を使うことが多いと思います。単純に Git tag と紐付けてファイルをアップロードする場所ですが、手作業でやるのも面倒なので CI と連携させるのが便利です。
Travis CI には Deployment の機能があります。その名の通り、アプリケーションのテスト/ビルド後に、外部の指定した場所へ成果物をデプロイする機能です。デプロイするトリガーとして「特定のブランチ」「git tag がプッシュされた場合のみ」「Go 1.7 ビルドのみ」のような条件が指定できます。
Deployment は、標準で GitHub Releases のインテグレーションを備えています (GitHub Releases Uploading - Travis CI)。GitHub Access Token だけ与えればあとはよしなにアップロードしてくれる便利君ですが、複数ファイルアップロードしたいときに難がありました。
file にアップロード対象のファイルを列挙する 公式ドキュメントで紹介されている方法です。以下は ec2c のバイナリパッケージを12個アップロードする例です。
https://docs.travis-ci.com/user/deployment/releases/#Uploading-Multiple-Files
deploy: provider: releases skip_cleanup: true api_key: $GITHUB_TOKEN file: - dist/ec2c-0.1.0-darwin-386.tar.gz - dist/ec2c-0.1.0-darwin-386.zip - dist/ec2c-0.1.0-darwin-amd64.tar.gz - dist/ec2c-0.1.0-darwin-amd64.zip - dist/ec2c-0.1.0-linux-386.tar.gz - dist/ec2c-0.1.0-linux-386.zip - dist/ec2c-0.1.0-linux-amd64.tar.gz - dist/ec2c-0.1.0-linux-amd64.zip - dist/ec2c-0.</description></item><item><title>PostgreSQL が起動したかどうか簡単に確認する (ping)</title><link>http://blog-ja.dtan4.net/posts/qiita-45ae1a8ac6f853a0dc1a/</link><pubDate>Wed, 07 Sep 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-45ae1a8ac6f853a0dc1a/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
PostgreSQL は、プロセスを起動してから SQL クエリ・外部入力を受け付けるようになるまで若干のタイムラグが有ります。特に Docker コンテナで起動した場合、自分の環境では5秒程度待つことになります。
The files belonging to this database system will be owned by user &amp;quot;postgres&amp;quot;. This user must also own the server process. The database cluster will be initialized with locale &amp;quot;en_US.utf8&amp;quot;. The default database encoding has accordingly been set to &amp;quot;UTF8&amp;quot;. The default text search configuration will be set to &amp;quot;english&amp;quot;. ... LOG: autovacuum launcher shutting down LOG: shutting down LOG: database system is shut down done server stopped PostgreSQL init process complete; ready for start up.</description></item><item><title>terraform import と Terraforming</title><link>http://blog-ja.dtan4.net/posts/2016-08-18-010652-hatenablog/</link><pubDate>Thu, 18 Aug 2016 01:06:52 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2016-08-18-010652-hatenablog/</guid><description>先日 Terraform 0.7 がリリースされました。 Terraform 0.7 の目玉機能は、なんと言っても既存リソースの import terraform import ではないでしょうか。全世界の Terraform ユーザが長年待ちわびていた機能がついに搭載されたことになります。 あ、あと terraform.tfstate のバージョンが 1 から 3 に上がったので後方互換性が地味に失われているのも大きいですね…
さて、自分は1年以上前から既存リソースをコード化する手段として Terraforming を開発し今に至るまでメンテナンスしてきました。
https://github.com/dtan4/terraforming
現在ではそれなりの認知をいただき、リソース追加などで Pull Request も多くもらうようになりました。 そんなことをしていたので、既存リソース import の公式対応には注目している、むしろしなければならないような立ち位置となっています。
本記事では、terraform import を試しつつ Terraforming がこの先生きのこれるのかどうかを見ていきたいと思います。
terraform import 概要 terraform import は、既存のリソースを Terraform の管理下に置くための機能です。Terraform 0.7 時点では、tfstate（Terraform がリソース管理状態を把握する JSON）のみ生成できます。人間が書く tf ファイルの生成はできません。
公式ドキュメントはこれ =&amp;gt; Import - Terraform by HashiCorp
This is a great way to slowly transition infrastructure to Terraform
とのことです。楽しみですね。</description></item><item><title>YAPC::Asia Hachioji 2016 で自作 PaaS について喋ってきた #yapc8oji</title><link>http://blog-ja.dtan4.net/posts/2016-07-04-230947-hatenablog/</link><pubDate>Mon, 04 Jul 2016 23:09:47 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2016-07-04-230947-hatenablog/</guid><description>というわけで、7/2-3 に開催された YAPC::Asia Hachioji 2016 に参加してきました。ついでに喋ってきました。
http://yapcasia8oji-2016mid.hachiojipm.org/
行ってきた YAPC は2013年から数えて4回目なのですが、毎回ワイワイとお祭り感があるのが参加していて楽しいです。 ワイワイしつつ、内容も面白い &amp;amp; 興味深い発表が多いですね。
SideCI の方の発表で、Terraforming 紹介してもらえてありがたかったです。 近いうちに Terraforming リポジトリへ SideCI 導入します。 あとマイクロソフトの DC の話が面白かったです。Cognitive Services とかも含めて、Azure 色々できるんだなーとか。
喋ってきた 仕事でやったネタをどっかで喋っておきたかった &amp;amp; 隣の席の先輩が応募していたので、自分も締め切り1分前に応募しました。そしたら無事採択され、今回登壇したという形です。非 LT でのちゃんとした？登壇は初めてですね。
仕事で PaaS を作ったので、それについて話しました。
https://speakerdeck.com/dtan4/number-yapc8oji
応募時にヒヨって15分枠で出してそのまま通ったわけですが、いざ資料を作ってみると15分に収まらなかったですね…発表ではデモ含めてギリギリだったのですが。 発表時間、仮に余ったらデモするなり余談するなりで埋める術はありますが短い場合だと削るしかなくて厳しいです。今後の教訓になりました。 あと、先輩が「Kubernetes 導入しました」と発表した1時間後に「自作 PaaS 導入した。ECS 入れたい」って発表するのはクレイジーでしたね…
Hosting Paus できたらいいですね〜
Paus 一応発表した Paus について簡単に紹介しときます。
https://github.com/dtan4/paus
Paus は、docker-compose.yml 書いて git push したらそれだけで Web アプリがデプロイできるというシンプルな PaaS です。とりあえす下のデモ動画で雰囲気を掴んでください:
Heroku とか OSS PaaS は便利だけど Buildpack + Addons 構成に縛られちゃう、もっと気軽にデプロイしたい。そういった流れで作りました。 全体的に荒削りですが、なんとか一通りのことはできるようになってます。</description></item><item><title>Kubernetes Meetup Tokyo #2 で LT してきた #k8sjp</title><link>http://blog-ja.dtan4.net/posts/2016-06-21-003142-hatenablog/</link><pubDate>Tue, 21 Jun 2016 00:31:42 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2016-06-21-003142-hatenablog/</guid><description>最近ちょくちょく人前出るようになったので、ちゃんと記録はしておこうと思いました。
六本木ヒルズの Google で開催された Kubernetes Meetup Tokyo #2 で LT してきました。
http://k8sjp.connpass.com/event/33508/
最近作った Kubernetes Secret を手軽に扱えるツール k8sec と Go Kubernetes API Client Library を使ったコードの書き方を紹介しました。準備不足感が否めなくて申し訳なかったです…。スライドはこれです。
https://speakerdeck.com/dtan4/writing-kubenetes-tools-in-go
(R, G, B) = (50, 109, 230) が Kubernetes の色っぽいです。
伝えたかったこととしては、
Ops だけでなく Dev が叩けるようなインターフェイスにしたい シェルスクリプトや書捨てスクリプトで運用するよりは、ちゃんとツールを作ったほうがいい API Client Library 使えば、ツール作るのもそう難しくはない です。
で、こいつが発表中に紹介した k8sec です。Heroku 使ってた人にとっては馴染みやすいと思うのですがどうなんでしょう…。
https://github.com/dtan4/k8sec
Kubernetes の運用は自分たちも検証段階ですが、各社それぞれ違った知見を持ちつつ同じような悩みを抱えてたりしているようでした。今回みたいな Meetup や Slack などで情報交換していけるとよさそうです。ありがとうございました。
(This post was imported from https://dtan4.hatenablog.com/entry/2016/06/21/003142)</description></item><item><title>CoreOS で ECS クラスタを構築する</title><link>http://blog-ja.dtan4.net/posts/qiita-a98ceb194ed4854bb300/</link><pubDate>Wed, 15 Jun 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-a98ceb194ed4854bb300/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
ECS クラスタを作るにあたって土台の EC2 インスタンスが必要となるわけですが、そこで使う AMI として公式では ECS-optimized AMI を推奨しています。ECS-optimized AMI は Amazon Linux AMI に新し目の Docker と ecs-agent、ecs-init スクリプトを同梱したやつです。初回チュートリアルでクラスタを立てる時もこの AMI が使われます。
ただ、実際のところ EC2 の中身に関しては (2016-06-15 時点)
Linux Kernel 3.10 以上で Docker 1.5.0 以上で ecs-agent コンテナが立ってる のであれば何でもよいのです。ECS-optimized AMI はそれを満たした推奨構成であるだけです。
というわけで、Docker 環境に特化した CoreOS を使ってみましょう。
ECS クラスタを準備 まっさらからクラスタ建てる場合は、Management Console なり ecs-cli なりで新しくクラスタを作ってください。 もしくは、既存クラスタにノード追加の形で CoreOS インスタンスを追加することもできます。
（ないなら）IAM Role ecsInstanceRole を作成 ecs-agent が ECS API にアクセスするため、その権限をインスタンスに付与してあげる必要があります。 初回チュートリアルでクラスタを立ち上げた場合は作られてると思いますが、まっさらからクラスタを構築する場合はこの Role がないので作る必要があります。
IAM -&amp;gt; Roles -&amp;gt; Create New Role を開く [AWS Service Role] の [Amazon EC2] を開き、AmazonEC2ContainerServiceforEC2Role にチェックを入れる [Create Role] 作った Role を開き、[Trusted Relationships] -&amp;gt; [Show policy document] が以下のようになっているのを確認。なってなかったら上書き。 { &amp;#34;Version&amp;#34;: &amp;#34;2008-10-17&amp;#34;, &amp;#34;Statement&amp;#34;: [ { &amp;#34;Sid&amp;#34;: &amp;#34;&amp;#34;, &amp;#34;Effect&amp;#34;: &amp;#34;Allow&amp;#34;, &amp;#34;Principal&amp;#34;: { &amp;#34;Service&amp;#34;: &amp;#34;ec2.</description></item><item><title>RubyGems 開発速習会</title><link>http://blog-ja.dtan4.net/posts/qiita-ea25b1c74346e330d5eb/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-ea25b1c74346e330d5eb/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
この記事は、RubyGem 開発速習会@Wantedly の資料として作られたものです :exclamation:
この資料は、
Ruby 2.3.1 RubyGems 2.5.1 Bundler 1.12.4 の環境で執筆されました。
この速習会のゴール gem を一から作れるようになる ただ作るだけじゃなく、テスト駆動開発を取り入れた効率のよい開発ができるようにある 開発支援系のサービスに詳しくなる gem とは gem は、最もメジャーな Ruby ライブラリの形式です。 Ruby on Rails も1つの gem として提供されており、rails gem の中でもまた多くの gem が利用されています。 現在公開されている Ruby のソフトウェアや Ruby on Rails 上の Web サービスは、多くの gem を組み合わせることで成り立っているのです。
ちなみに www.wantedly.com では、Gemfile に書いてあるだけで__164個__の gem が使われています。
$ cat Gemfile | grep -E &amp;#39;^\s*gem&amp;#39; | wc -l 164 gem をインストールしたり探したりするときは、gem コマンドを利用します。</description></item><item><title>Kubernetes の Go API クライアントライブラリを使って Kubernetes を直接操作する</title><link>http://blog-ja.dtan4.net/posts/qiita-f2f30207e0acec454c3d/</link><pubDate>Fri, 20 May 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-f2f30207e0acec454c3d/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
2016/11/15 10:15 追記
この記事では kubernetes/kubernetes リポジトリに含まれているクライアントライブラリを紹介していますが、今年の8月だか9月になって API クライアントだけが別リポジトリとして切り出されました。
https://github.com/kubernetes/client-go
今後何かツールを作るときは、この client-go を使うのがよいでしょう。
というわけで、以下の内容は__記事初公開時点の、client-go がなかった時代の__ものとなっております。その点ご留意いただいた上でお読みください。
追記終わり
あまり知られてないようですが、Kubernetes には公式の Go 製 API クライアントライブラリがあります。kubectl もこのライブラリを用いて実装されています。
https://github.com/kubernetes/kubernetes/tree/master/pkg/client/
kubectl は確かに万能なんですが、実運用に投入するとなるとその万能さがマイナスに効いてくることもあります。で、自分たちが使いやすいように kubectl をラップした何かを作りたくなるのですが、他の言語から kubectl をサブコマンド呼び出しするのは筋が悪いです。API ライブラリを使ってネイティブレベルで Kubernetes を操作するようにしましょう。
いきなりサンプルコード というわけで、Pod の名前一覧を表示するだけのサンプルコードです。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;os&amp;#34; &amp;#34;k8s.io/kubernetes/pkg/api&amp;#34; client &amp;#34;k8s.io/kubernetes/pkg/client/unversioned&amp;#34; &amp;#34;k8s.io/kubernetes/pkg/client/unversioned/clientcmd&amp;#34; ) func newKubeClient() (*client.Client, error) { loadingRules := clientcmd.NewDefaultClientConfigLoadingRules() loadingRules.ExplicitPath = clientcmd.RecommendedHomeFile loader := clientcmd.NewNonInteractiveDeferredLoadingClientConfig(loadingRules, &amp;amp;clientcmd.ConfigOverrides{}) clientConfig, err := loader.ClientConfig() if err != nil { return nil, err } kubeClient, err := client.</description></item><item><title>「クラウド開発徹底攻略」を読んだ</title><link>http://blog-ja.dtan4.net/posts/2016-05-17-021835-hatenablog/</link><pubDate>Tue, 17 May 2016 02:18:35 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2016-05-17-021835-hatenablog/</guid><description>技術評論社さんのクラウド開発徹底攻略 (WEB+DB PRESS plus) を、特集「Docker 実戦投入」を執筆された @spesnova さんよりご恵贈いただきました。ありがとうございます。
おなじみ徹底攻略シリーズということで過去に WEB+DB Press 誌に掲載された記事を再編集したものなんですが、再掲載までおよそ1年分のアップデートが各記事にしっかりと反映されているようでした。クラウドや Docker 界隈は移り変わりが激しいので、最新情報をまとめて書籍でおさらいできるのは非常にありがたいです。
記事は「AWS 自動化」「Docker 実戦投入」といった一歩進んだ実運用の話のほか、Google Cloud Platform と Heroku の入門や BigQuery, Amazon SNS の活用まで、今時のクラウドインフラのトピックが幅広く抑えられています。Docker とか BigQuery とかってよく聞くしググれば情報は出てくるけど、じゃあベストプラクティスは？と言われると見つけにくいところがあります。そういった点で本書は一通りのプラクティスがまとまっており、おすすめです。実際の運用例だけでなく、サービスの哲学や大本の仕組みについて解説されている点も良かったです。
特に Docker 界隈は Kubernetes がメジャーになり、ベストプラクティスがここ1年で大きく移り変わってきた感じがあります。本書の「Docker 実戦投入」はその進化に追従し、全体的に、特に後半の運用話が大幅にアップデートされています。元記事ではオーケストレーションに Capistrano を使っていましたが、本書では全面的に Kubernetes を使うようになっています。そういや当時は Docker Swarm や Kubernetes がベータで、実運用投入するならどれがいいのかと悩んでましたね…。Rails アプリの運用を題材に一通りの操作が抑えてあるので、今時の Docker 事情を知りたい方や Kubernetes 導入を考えている方は参考になると思います。
というわけで、今時のクラウドインフラ事情を掴んでおきたい方、いまはオーソドックスに AWS や Docker を使っているけど一歩進んだ使い方を知りたい方はマストバイな一冊です。 自分も AWS 自動化で触れられているツールや GCP はこれまであまり触ってなかったので、これを期におさらいしておきたいです。
(This post was imported from https://dtan4.hatenablog.com/entry/2016/05/17/021835)</description></item><item><title>CoreOS で Docker デーモンの起動オプション DOCKER_OPTS を設定する</title><link>http://blog-ja.dtan4.net/posts/qiita-2212607d13ad7c81120e/</link><pubDate>Mon, 16 May 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-2212607d13ad7c81120e/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
CoreOS は何もしなくとも自動で Docker デーモンが立ち上がりますが、たまに Docker デーモン自体の起動オプション (DOCKER_OPTS) を設定したい時があります。Docker デーモンへのアクセスには TLS 認証使いたいとか、overlay network を使うための下準備をしたいとかです。
そういう時は、cloud-config の units に docker.service を記述することで Docker デーモンの起動時に DOCKER_OPTS を設定できます。 以下の例では、etcd を利用した overlay network 構築 のオプションを指定しています。
coreos: units: - name: etcd2.service command: start - name: docker.service # &amp;lt;===== drop-ins: - name: 10-cluster-config.conf content: | [Service] Environment=&amp;#34;DOCKER_OPTS=--cluster-store=etcd://0.0.0.0:2379 --cluster-advertise=eth0:2375&amp;#34; REF Customizing docker</description></item><item><title>wercker の新機能 Wercker Workflows を試す</title><link>http://blog-ja.dtan4.net/posts/qiita-9bcf5dbfd3dbbd87472b/</link><pubDate>Mon, 16 May 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-9bcf5dbfd3dbbd87472b/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
プライベートリポジトリの CI 無料でお馴染みの wercker が、先日ワークフロー機能 Wercker Workflows をリリースしました。
とりあえず、以下の公式デモ動画を観れば何ができるのかわかると思います。
ブログ記事 :point_right: Introducing Wercker Workflows デモ動画 :point_right: Wercker Workflows - YouTube
Wercker Workflows とは いわゆるワークフロー機能というやつで、1つの CI プロセスを複数のパイプラインに分割して組み合わせる機能です。Jenkins とか、最近だと Concourse CI でお馴染みの機能です。
パイプラインは従来の build, deploy に相当するもので、1つの CI プロセス内におけるタスクの分割単位となります。従来は build, deploy の2つしか記述できなかったところ、test や push-dev のように複数種類のパイプラインを記述できるようになったのが今回の Workflows です。
以下の例では、Build, Tests, Push to registry, Notify Scheduler の4つのパイプラインを直列に実行しています。これだけだと従来の wercker とあまり変わりません。
_image from: http://wercker.com/workflows/_
Workflows では、複数のパイプラインを__並列に__実行することができます。以下の例は、ビルド後に開発用 (dev) イメージの push &amp;amp; deploy と本番用 (release) イメージの push &amp;amp; deploy を並列に実行しています。</description></item><item><title>Go でコメントアウトせずに素早く複数行スキップさせる</title><link>http://blog-ja.dtan4.net/posts/qiita-5efab45307203c46e424/</link><pubDate>Mon, 18 Apr 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-5efab45307203c46e424/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
TL; DR if false {} でスキップしたい箇所を囲む
本文 Go では宣言されてるのに使われてない変数があると、ビルド時に hoge declared and not used といった感じで怒られます。 Go 書いてる時、デバッグ目的で処理を飛ばそうと複数行コメントアウトしたくなる時があります。が、適当にやると変数の宣言だけが残って前述のように怒られることがあります。この場合は改めて宣言箇所だけコメントアウトすればビルドが通りますが、まあ面倒ですよね。
こういう時は、該当箇所を if false {} で囲ってやればよいです。見てわかるように、常に false なのでブロックの中は実行されません。
Example 元のコード package main import ( &amp;#34;fmt&amp;#34; ) func main() { hogeMessage := &amp;#34;hoge&amp;#34; fugaMessage := &amp;#34;fuga&amp;#34; piyoMessage := &amp;#34;piyo&amp;#34; hogehogeMessage := &amp;#34;hogehoge&amp;#34; fmt.Println(hogeMessage) fmt.Println(fugaMessage) fmt.Println(piyoMessage) fmt.Println(hogehogeMessage) } $ go run hoge.go hoge fuga piyo hogehoge コメントアウトすると… package main import ( &amp;#34;fmt&amp;#34; ) func main() { hogeMessage := &amp;#34;hoge&amp;#34; fugaMessage := &amp;#34;fuga&amp;#34; piyoMessage := &amp;#34;piyo&amp;#34; hogehogeMessage := &amp;#34;hogehoge&amp;#34; fmt.</description></item><item><title>Ubuntu や Alpine Linux をワンコマンドで瞬時に立ち上げる</title><link>http://blog-ja.dtan4.net/posts/qiita-3be396665f9305428f4f/</link><pubDate>Thu, 14 Apr 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-3be396665f9305428f4f/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
alpine コマンド、centos コマンド、ubuntu コマンド Docker 環境を用意して以下のエイリアスを .bashrc なり .zshrc に書いておくと、ワンコマンドで Linux の対話環境が立ち上がって便利
alias alpine=&amp;#39;docker run -it --rm alpine:3.3 /bin/sh&amp;#39; alias centos=&amp;#39;docker run -it --rm centos:7 /bin/bash&amp;#39; alias ubuntu=&amp;#39;docker run -it --rm ubuntu:14.04 /bin/bash&amp;#39; $ alpine / # apk update fetch http://dl-cdn.alpinelinux.org/alpine/v3.3/main/x86_64/APKINDEX.tar.gz fetch http://dl-cdn.alpinelinux.org/alpine/v3.3/community/x86_64/APKINDEX.tar.gz v3.3.3-20-gb700737 [http://dl-cdn.alpinelinux.org/alpine/v3.3/main] v3.3.3-9-gfc38db2 [http://dl-cdn.alpinelinux.org/alpine/v3.3/community] OK: 5858 distinct packages available $ centos [root@dfaaba07c44b /]# yum update Loaded plugins: fastestmirror, ovl base | 3.6 kB 00:00:00 extras | 3.</description></item><item><title>Alpine Linux でタイムゾーンを変更する</title><link>http://blog-ja.dtan4.net/posts/qiita-8359e389b95cbc60952d/</link><pubDate>Sat, 06 Feb 2016 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-8359e389b95cbc60952d/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
スリムな Docker イメージを作るため、gliderlabs/alpine イメージをベースにバイナリを一個だけポンと置いて運用するみたいなことをしています。 gliderlabs/alpine イメージは（というかほとんどの OS イメージは）タイムゾーンが GMT (UTC+0) のままなので、時刻依存の作業をさせるときには気をつけないといけません。日本時間 (UTC+9) の感覚で書いたら、9時間遅れて実行されたとかログの時刻がずれるとか起こりえます。
まっさらの状態で date を打つと…
$ docker run --rm gliderlabs/alpine:3.3 date Sat Feb 6 06:47:37 UTC 2016 タイムゾーンの設定 メジャーな Linux ディストリビューションと同じく、/etc/localtime を変更すればよいです。zoneinfo とかはそのままだと用意されていないので、apk で tzdata パッケージをインストールする必要があります。
Dockerfile で日本標準時 Asia/Tokyo に設定する場合は以下のようになります。ここで欲しいのは /usr/share/zoneinfo/Asia/Tokyo だけなので、tzdata はそれだけ抜き取ったら消しちゃいます。
FROMgliderlabs/alpine:3.3RUN apk --update add tzdata &amp;amp;&amp;amp; \ cp /usr/share/zoneinfo/Asia/Tokyo /etc/localtime &amp;amp;&amp;amp; \ apk del tzdata &amp;amp;&amp;amp; \ rm -rf /var/cache/apk/*この Dockerfile からビルドしたイメージで date を叩くと…</description></item><item><title>Emacs で行番号を指定してファイルを開く</title><link>http://blog-ja.dtan4.net/posts/qiita-9e2eb59373f0b2b5f17c/</link><pubDate>Sat, 26 Dec 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-9e2eb59373f0b2b5f17c/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
:bulb: 以下、emacs の部分は、あなたの Emacs 利用形態（新しい Emacs ではなくすでに起動している Emacs 上で開くとか）に合わせて emacsclient -n とかにしてください。
ターミナルから行番号を指定して開く Emacs のコマンドラインヘルプを見ると…
$ emacs --help Usage: /usr/local/opt/emacs-mac/bin/emacs [OPTION-OR-FILENAME]... Run Emacs, the extensible, customizable, self-documenting real-time display editor. The recommended way to start Emacs for normal editing is with no options at all. (snip) Action options: FILE visit FILE using find-file +LINE go to line LINE in next FILE +LINE:COLUMN go to line LINE, column COLUMN, in next FILE (snip) ということで、/path/to/hoge ファイルの__20行目__を開くときは</description></item><item><title>GitHub にパスワードとかセンシティブなファイルを push してしまったときの対処法</title><link>http://blog-ja.dtan4.net/posts/qiita-34e41e3bd40a43fd8cbf/</link><pubDate>Sat, 19 Dec 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-34e41e3bd40a43fd8cbf/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
.gitignore し忘れて他人に見えちゃマズいファイル（パスワードをベタ書きしたファイルや AWS_SECRET_ACCESS_KEY を書いたファイルとか）を git commit しちゃった！そんなときは
$ git reset --hard HEAD~ すればすぐ何もなかったことにできます。
が！そこで気付かずに GitHub へ git push してしまった！こうなると容易に何もなかったことにはできません。
この記事では、こういうときに何もなかったことにする方法を紹介します。
そのデータを無効にする 特に Public Repository の場合はすでにそのデータが他人の目に触れていた…ということも十分ありえます。AWS_SECRET_ACCESS_KEY なんかは取得用のクローラが存在するとも聞きます。ので、まずは不正利用されても影響が出ないように、__パスワードの書き換えやトークンの無効化__を施しましょう。
（この時点でもう何もなかったことになってない気がする）
git の履歴から該当のファイルを消す git reset と git filter-branch 2つの方法があります。
git reset (2015-12-29 15:00 追記) git reset だとセンシティブファイル以外の作業履歴もすべて消去されてしまうので、それらを残しておきたい場合は後述 git filter-branch でコミットを書き換えるようにしてください。 (追記終わり)
該当ファイルを git commit してすぐ気づいた (3コミット以内) なら、まだ git reset で消せます。
$ git reset --hard HEAD~2 ＃ 消すコミットの数 git filter-branch 気づいたのはそこから何コミットもしたあと…だと git reset でそこまでの履歴を全部消すのは現実的ではありません。そんな時に役立つのが git filter-branch です。filter-branch は普段見慣れない（であってほしい）ですが、__大量のコミットを機械的に書き換える__コマンドです。今回みたいにファイルを消す以外にも、リポジトリ全体のコミットオーサーの書き換えとかも一発でできます。</description></item><item><title>Terraform と CI で実現するインフラのコード化と構築の自動化</title><link>http://blog-ja.dtan4.net/posts/qiita-ab1671d657f1571e59d8/</link><pubDate>Sat, 19 Dec 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-ab1671d657f1571e59d8/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Wantedly Advent Calendar 2015 __18__日目です。
インフラチームインターンの @dtan4 です。
Wantedly では Terraform を用いたインフラのコード化 (Infrastructure as Code) を全面的に取り入れています。インフラリソースの追加や修正は、コードを書くこと・CI 上での自動適用によって行われています。
この記事では、今年5月から半年以上の間 Terraform を運用してきた中での
なぜ Terraform でインフラをコード化しようとしたのか どのように Terraform を運用しているのか Terraform 運用にあたって注意すべき点 既存リソースから Terraform コードを生成する Terraforming について ということを紹介したいと思います。
Terraform とは Terraform は、Vagrant などで有名な HashiCorp が作っている__コードからインフラリソースを作成する・コードでインフラを管理する__ためのツールです。AWS, GCP, Azure, DigitalOcean といったクラウドプロバイダや DNSimple, Mailgun, Rundeck を含む多くの SaaS に幅広く対応しています。
コードは JSON 互換である HCL (HashiCorp Configuration Language) で記述します。例えば AWS ELB と EC2 インスタンスは
# from https://www.</description></item><item><title>Crystal で AWS API を叩く</title><link>http://blog-ja.dtan4.net/posts/qiita-0a93c42a44f9e6cb8b48/</link><pubDate>Wed, 16 Dec 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-0a93c42a44f9e6cb8b48/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
この記事は Crystal Advent Calendar 2015 の16日目の記事です :exclamation:
昨日の記事は @pine613 さんの 『 東京 Crystal 勉強会 #3 in 恵比寿 』 を開催します!!!! でした。1/22 に第三回を開催とのことでぜひ参加したいのですが、3日後の 1/25 が修論提出日だったりします。善処できるよう努力します。
さて、今回は Crystal で AWS の API を叩いてみた、というお話です。
Crystal から AWS を触りたい 普段 AWS なインフラやってる人間なので、Crystal で AWS を操作できないものかと考えました。やっぱネイティブバイナリ吐けるっていうのはツール作る人間にとって魅力的なんですよ…
Ruby, Python, JavaScript, Java, Go, &amp;hellip; といったいわゆるメジャーな言語から AWS を操作する場合は、AWS が公式に提供している SDK を使うのが一般的です。提供言語の一覧は以下のページに有ります。
AWS のツール | アマゾン ウェブ サービス（AWS 日本語）
ですが、ご覧のとおり Erlang/Elixir や Crystal といったマイナーな言語についてはまだ SDK は提供されていません。Erlang/Elixir は一部サービスに対応した非公式 SDK gleber/erlcloud があります。が、俺たちの Crystal には非公式 SDK すらありません。</description></item><item><title>プロダクトに名前をつける時に気をつけたいこと</title><link>http://blog-ja.dtan4.net/posts/qiita-639928bcfc6ac0a69a57/</link><pubDate>Mon, 14 Dec 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-639928bcfc6ac0a69a57/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
私は今まで、数々のアプリケーションやライブラリをつくって GitHub / RubyGems 等で公開してきました。ここで毎回注意しているのが__プロダクトの名前の付け方__です。この記事では、自分が何に気をつけて名付けをしているのかを紹介します。
ユニークな名前にする ユニークな名前にする、つまり__既に公開されているものとなるべく名前が被らないようにすべき__です。ユニークな名前にすることでググラビリティ（検索した時のヒットしやすさ）を高めることができますし、エゴサーチもしやすくなります。
同じ名前のプロダクトがすでに存在しないかチェックする 自分はよさ気な名前が思いついたら、まず Google 検索と GitHub の一番上にある検索ボックスに突っ込みます。同じ名前のリポジトリがすでにあるかどうかを調べるためです。ハイフンとかを含めるなら名前をダブルクォートで囲むのが良いでしょう。
幸運にもリポジトリが一件もヒットしない場合は、その名前を採用します。もしヒットした場合でも、数が少ない &amp;amp; 全然開発されていなかったり (Initial commit だけみたいな)、Star が全然ついてない場合は採用することがあります。自分のほうが有名になってやるぞ！という勢いです。
プロダクトを RubyGems や npm などのパッケージ管理システムに上げる場合は、そこでも名前を検索する必要があります。ここで被っているとさすがに登録できないので…
DeNA が作っている JSX と React.js の JSX や、プログラミング言語 Go と Thoughtworks が出してる GoCD とか、正直どうしてぶつかった感があります…
辞書に載っているような単語はなるべく避ける 英語の普通名詞や固有名詞はなるべく避けた方がいいです。よほどそのプロダクトが（それこそ Ruby とか Go みたいに）ヒットしない限り、その名前単体で Google 検索して引っかかることは相当厳しいでしょう。
とはいえ、適当にタイプした母音のないような単語は好ましくありません。発音しにくい &amp;amp; 覚えにくいというのはマイナスです。単語をそのまま使わず、少しもじったり組み合わせたりするとよいでしょう。フレーズを作って、単語の頭文字をつなげ合わせるのもよいです。Linux (Linux Is Not UniX) のような再帰的頭字語を作れるとカッコいいです。
あるいは、英語以外の単語・フレーズで考えるとユニーク性は増します。Google 翻訳の左欄に日本語なり英語の単語を入れて、右欄の言語を変えまくってよさそうな表記を探したりします。
ラテン語とかエスペラントとかはそうそう被らないでしょう（README に説明を書くべきだとは思いますが）。日本語のローマ字表記や中国語のピンインも意外と穴場だったりします。
キーボードでタイプしやすい名前にする :warning: 世の中 Dvorak 配列とか AZERTY 配列とかありますが、自分は大多数を占める QWERTY 配列における打ちやすさを考えています。 :warning:</description></item><item><title>クラウドサービスを活用して README にバッジをペタペタ貼る</title><link>http://blog-ja.dtan4.net/posts/qiita-13b0ea9edf5b99926446/</link><pubDate>Sat, 31 Oct 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-13b0ea9edf5b99926446/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
最近の GitHub に上げてある OSS リポジトリには、README にいろんなバッジが貼られています。リポジトリに連携しているクラウドサービスのステータスを表すものがほとんどです。 自分は README にバッジを貼りたい派です。たとえば dtan4/terraforming だとこういう感じです。
最近はバッジの種類も増えているので、整理のためにもどういうのがあるかまとめてみようと思います。
自分がよく README に貼っているバッジ 自分が書く RubyGems については、以下の6個のバッジを必ずつけるようにしています。
Travis CI
言わずと知れた CI サービス。現在の master が CI 通っている (passing) かコケている (failed) かがわかります。リポジトリのメンテナンス状況を把握するのによいです。
クリックすれば、そのリポジトリのテスト結果を見ることができます。
Code Climate
ソースコードの品質チェックをしてくれるサービスです。リポジトリ内のコード重複や複雑性を解析して GPA (最高 4.0) を算出してくれます。このリポジトリのコード品質がどうであるか、をひと目で確認できます。Ruby の他にも Node.js や PHP, Python に対応してます。
最近はテストカバレッジの取得にも対応しました。Travis CI のテスト後にテストカバレッジが Code Climate へアップロードされます。 以前はテストカバレッジの表示に Coveralls を使っていましたが、Code Climate でひとまとめに見られるようになったので最近はこっちを使うようにしています。
クリックすれば、そのリポジトリの詳細な解析結果と行単位のテストカバレッジを見ることができます。
Gemnasium
アプリケーションの依存管理をチェックしてくれるサービスです。Ruby だと Gemfile, Gemfile.lock, *.gemspec を解析し、指定されている依存ライブラリのバージョンが古くなったら警告を出してくれます。Ruby の他にも Node.</description></item><item><title>最近書いた Datadog にメトリクスを送りつけるツール</title><link>http://blog-ja.dtan4.net/posts/2015-10-18-181932-hatenablog/</link><pubDate>Sun, 18 Oct 2015 18:19:32 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2015-10-18-181932-hatenablog/</guid><description>日頃インフラメトリクスの監視には Datadog を使っています。最近せっかくなのでインフラ以外の色々も Datadog で監視したくなったので、メトリクス中継用のツールを2個ほど作りました。せっかくなので紹介します。
SendGrid2Datadog (SendGrid events) https://github.com/dtan4/sendgrid2datadog
メール配信サービスである SendGrid のイベントを Datadog 上で監視できるようにするやつです。
いまどのくらいメールが送られているかというのをパッと確認できるようにしたいと思い作りました。インフラメトリクスが置いてあるダッシュボードにこのグラフを同居させてあるため、DB 負荷が上がった時にも効率よく確認することができます。
SendGrid2Datadog 自体は Heroku 上で動作しています。
実装 SendGrid2Datadog は小さな Web アプリケーション (Ruby + Sinatra) として実装されてます。SendGrid にはメール送信や送信失敗のイベントごとに Webhook を投げる機能があるため、それを受けて都度 Datadog にイベント発生を送信するようにしています。 Datadog への送信は Dogstatsd を使っています。
Spotdog (EC2 Spot Instance History) https://github.com/dtan4/spotdog
AWS EC2 には価格変動型のスポットインスタンスというのがあります。このスポットインスタンスの価格推移を Datadog 上で監視できるようにするやつです。
この価格推移グラフ、一応 Management Console にログインすれば見れるのですがまあ面倒です。複数インスタンスタイプの一覧表示とかできません。
なので、Datadog 上で見られるように、自分の好きなようにグラフを組めるように Spotdog を作りました。上の図にあるようにオンデマンド価格を閾値として表示できるため便利です。オンデマンド価格を超えたらアラート飛ばすとかももちろん可能です。
惜しいのは、値が小数点第二位までしか表示できないことでしょうか（グラフ上は反映されてる）。c4.xlarge あたりだと小数点第三位での動きが多いのでそのへん確認できないのはつらいです。まあグラフでだいたいの推移を確認できるのでよいでしょうか。
Spotdog も Heroku 上で動作しています。ただ、こいつは後述するようにコマンドラインツールなので Heroku Scheduler で10分おきに叩くようにしています。
実装 Spotdog は Ruby なコマンドラインツールです。Docker image もあります (quay.</description></item><item><title>tmux で Prefix key が押されているかどうかを表示する</title><link>http://blog-ja.dtan4.net/posts/qiita-363e92525e7c5a16f3fc/</link><pubDate>Wed, 07 Oct 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-363e92525e7c5a16f3fc/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
tmux でペイン分割とかウィンドウ作成するときとかにキーバインドとして使う Prefix key (C-b とか C-t とか設定されてる) ですが、誤動作を防ぐためにいま Prefix key が押されているのかどうなのか視覚的に確認したいことがあります。
以下のように .tmux.conf を書くことで、Prefix key が押された時に Status line の色を下動画のように反転させられます。
set-option -g status-left '#[fg=cyan,bg=#303030]#{?client_prefix,#[reverse],} #H[#S] #[default]' (Prefix key は C-t に設定)
重要なのはこれ
#{?client_prefix,#[reverse],} .tmux.conf では ?&amp;lt;condition&amp;gt;,&amp;lt;true action&amp;gt;,&amp;lt;false action&amp;gt; の形で三項演算子をかけます。で、client_prefix は Prefix key が押されていたら 1 (true) になるというわけです。 今回は色を変えただけですが、押されている / いないときだけ何かしら文字を表示することももちろん可能です。
注意点があって、例えば Prefix key が押された時だけ黄色背景黒文字 (fg=black, bg=yellow) にしようとして
#{?client_prefix,#[fg=black,bg=yellow],} と愚直に書くと
のように表示がバグります。#[fg=black,bg=yellow] 内のコンマが三項演算子2つめのコンマと解釈されているようです。
こうしたいときは、#[] を分割すればよいです。
#{?client_prefix,#[fg=black]#[bg=yellow],} REF give a hint when press prefix key in tmux - Stack Overflow OpenBSD manual pages (tmux)</description></item><item><title>awscli + jq + peco + tmux-cssh を使って複数 EC2 インスタンスへ簡単 SSH</title><link>http://blog-ja.dtan4.net/posts/qiita-88545bbd2dcdb590b5a7/</link><pubDate>Mon, 28 Sep 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-88545bbd2dcdb590b5a7/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
TL;DR 必要なもの (awscli, jq, peco, tmux, tmux-cssh) をすべて入れた状態で
$ sh -c &amp;#34;tmux-cssh -i &amp;lt;ssh_key&amp;gt; -u &amp;lt;ssh_user&amp;gt; $(aws ec2 describe-instances | jq -r &amp;#39;.Reservations[] | .Instances[] | select(.State.Name != &amp;#34;terminated&amp;#34;) | select(has(&amp;#34;PublicIpAddress&amp;#34;)) | [.PublicIpAddress,.PrivateIpAddress,.State.Name,(.Tags[] | select(.Key == &amp;#34;Name&amp;#34;) | .Value // &amp;#34;&amp;#34;)] | join(&amp;#34;\t&amp;#34;)&amp;#39; | peco | awk &amp;#39;{ print $1 }&amp;#39; | tr &amp;#39;\n&amp;#39; &amp;#39; &amp;#39;)&amp;#34; とすることで、peco で EC2 インスタンスを選んで同時に SSH アクセスすることができます。
:warning: tmux 上で生活している方は、一度 tmux detach して tmux の外に出ないと tmux-cssh が実行できません。 また、ターミナル起動時に自動で tmux を立ち上げる設定は無効化しておく必要があります。</description></item><item><title>CoreOS でも tcpdump したい (CoreOS toolbox)</title><link>http://blog-ja.dtan4.net/posts/qiita-50fd75b56660ed8aa158/</link><pubDate>Mon, 28 Sep 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-50fd75b56660ed8aa158/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
CoreOS 上でも tcpdump でネットワークデバッグする話です。
tcpdump くらいあるやろ core@core-01 ~ $ tcpdump -bash: tcpdump: command not found 無いんですよねー
CoreOS toolbox https://github.com/coreos/toolbox
CoreOS は OS 本体に何も入ってない（からアプリケーションは Docker コンテナとして動かす）ことで有名ですが、上記のように tcpdump すら入ってないので特に低レイヤーの調査で困ることがあります。それを補助するために、CoreOS が公式に toolbox というのを提供しています。
実際に使ってみましょう。
core@core-01 ~ $ /usr/bin/toolbox latest: Pulling from fedora 48ecf305d2cf: Pull complete ded7cd95e059: Pull complete fedora:latest: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security.</description></item><item><title>Emacs で Crystal を書く</title><link>http://blog-ja.dtan4.net/posts/qiita-b098d11e48453e1c6ee0/</link><pubDate>Sat, 01 Aug 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-b098d11e48453e1c6ee0/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
みんな大好き Emacs で Crystal を書くための記事です。
Ruby ライクなシンタックスを持っているということもあって意外と ruby-mode でいけるのでは感はあります。実際、Crystal 独自機能を使わないようなコードを書く分には十分です。 ただ、型宣言とかマクロのような Crystal 独特のものを書こうとすると ruby-mode ではシンタックスハイライトが死にます。やはり Crystal に合わせたメジャーモードを使いたいところです。
ruby-mode でマクロを表示させた時の悲しい例: そして Crystal Wiki の Editor support で Emacs がハブられている！どういうことだ！
メジャーモード jpellerin/emacs-crystal-mode
crystal-mode があります。が、このメジャーモードは今のとこ MELPA とかに登録されている気配が無いです… 1 el-get 使いなら以下の一文を init.el にでも書いときましょう。
(el-get-bundle jpellerin/emacs-crystal-mode) マクロもちゃんとハイライトされてます。String interpolation がまだあやしいけど… 自分は使ってないですが、flycheck 用のコードも入っているみたいです。
マイナーモード マイナーモードに関しては、Ruby のものを流用することができます。 たとえば、
ruby-block end に対応する行をハイライトしてくれる ruby-end def, if 等に対応した end を自動で挿入してくれる (add-hook &amp;#39;crystal-mode-hook &amp;#39;ruby-block-mode) (add-hook &amp;#39;crystal-mode-hook &amp;#39;ruby-end-mode) そのほか Projectfile は crystal-mode で開くよう設定しておきましょう。</description></item><item><title>Terraforming で既存のインフラを Terraform 管理下におく</title><link>http://blog-ja.dtan4.net/posts/qiita-345c56281ab0e87d6646/</link><pubDate>Mon, 22 Jun 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-345c56281ab0e87d6646/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Terraform は、主にインフラをスクラッチから構築する際に有用なツールです。 ですが、いま動いている既存のインフラに Terraform を導入したい、既存のインフラを Terraform で管理したいと思う方もいるのではないでしょうか。 今回は、Terraforming を使って既存のインフラを Terraform で管理できるようにする方法を紹介します。
Terraforming とは Terraforming は、AWS の API を叩いて既存のインフラリソースから Terraform のコードを生成するツールです。 兄弟分に、DNSimple 用の Terraforming::DNSimple があります。
インストール RubyGems として公開されているので、
$ gem install terraforming また、Docker Image も公開してあるので、そちらを使いたい方は
$ docker pull quay.io/dtan4/terraforming:latest 使い方 tf 形式の出力 予め AWS のクレデンシャルを環境変数に入れておきます。 Mac ユーザなら envchain おすすめです。
export AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXXXXXXXX export AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx export AWS_DEFAULT_REGION=xx-yyyy-0 リソース名を指定するだけだと、tf 形式で出力されます。 S3 bucket の場合だと:
$ terraforming s3 resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;hoge&amp;#34; { bucket = &amp;#34;hoge&amp;#34; acl = &amp;#34;private&amp;#34; } resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;fuga&amp;#34; { bucket = &amp;#34;fuga&amp;#34; acl = &amp;#34;private&amp;#34; } これを s3.</description></item><item><title>Terraforming: 既存のインフラリソースを Terraform コードに落としこむ</title><link>http://blog-ja.dtan4.net/posts/2015-06-20-181559-hatenablog/</link><pubDate>Sat, 20 Jun 2015 18:15:59 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2015-06-20-181559-hatenablog/</guid><description>インフラ界隈のみなさま、 Terraform 使ってますか？ 導入したいけど、既存のリソースの管理をどうするか悩んでないですか？
少し前からこの問題を解決する Terraforming というツールを作っていて、今回 v0.1.0 を公開したので紹介します :tada:
https://github.com/dtan4/terraforming
https://rubygems.org/gems/terraforming
これはなに Vagrant で有名な HashiCorp が開発している Terraform というインフラをコードで管理するためのツールがあります。 Infrastructure as Code というやつです。 Terraforming は、AWS の API を叩いていま動いている既存の AWS リソースから Terraform のコードを生成するツールです。
インストール RubyGems として公開されているので、
$ gem install terraforming Docker Image も用意しているので、そちらを使いたい方は
$ docker pull quay.io/dtan4/terraforming:latest 使い方 予め AWS のクレデンシャルを環境変数に入れておきます。 Mac ユーザなら envchain おすすめです。
export AWS_ACCESS_KEY_ID=XXXXXXXXXXXXXXXXXXXX export AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx export AWS_DEFAULT_REGION=xx-yyyy-0 リソース名を指定するだけだと、tf 形式で出力されます。 S3 bucket の場合だと:
$ terraforming s3 resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;hoge&amp;#34; { bucket = &amp;#34;hoge&amp;#34; acl = &amp;#34;private&amp;#34; } resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;fuga&amp;#34; { bucket = &amp;#34;fuga&amp;#34; acl = &amp;#34;private&amp;#34; } これを s3.</description></item><item><title>Amazon S3 で Terraform の状態管理ファイル terraform.tfstate を管理 / 共有する</title><link>http://blog-ja.dtan4.net/posts/qiita-04632f1c2f35388a3283/</link><pubDate>Mon, 11 May 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-04632f1c2f35388a3283/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
2017-06-17: この記事はもう古いです。Terraform v0.8.x 以下を対象としています。 2017/03 にリリースされた Terraform v0.9.0 で remote config 周りの仕様が大きく変わりました。 S3 に置くファイル形式は変わってないですが、特に CLI 周りで後方互換性のない変更が入っています。例えば terraform remote コマンドが無くなっています。
詳しくは以下の公式ドキュメントを読んで下さい。
Backends - Terraform by HashiCorp Backends: Migrating From 0.8.x and Earlier - Terraform by HashiCorp というわけで、以下の記事は Terraform v0.8.x 以下を対象としたものになります。
2015-05-08 にリリースされた Terraform v0.5.0 にて Terraform の状態管理ファイルである terraform.tfstate を Amazon S3 で管理する機能が追加されたので、試してみました。
S3 Remote State Backend by apparentlymart · Pull Request #1723 · hashicorp/terraform
前置き: terraform.tfstate の管理とか共有 terraform.</description></item><item><title>PostgreSQL コンテナの backup / restore をする</title><link>http://blog-ja.dtan4.net/posts/qiita-5147a3f858d5919965c9/</link><pubDate>Thu, 23 Apr 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-5147a3f858d5919965c9/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker コンテナとして動いている PostgreSQL からデータを backup する、またデータを restore する（PostgreSQL コンテナにデータを注入する）方法です。 ここで使っているイメージは Docker Hub 公式の postgres イメージです。今回は postgres:9.4.1 を使いました。
$ docker run -d -p 5432:5432 --name postgres postgres:9.4.1 backup する $ docker exec [container_id or name] pg_dumpall -U postgres &amp;gt; dump.sql コンテナ内のデータベース全体が SQL として dump されます。
-- -- PostgreSQL database cluster dump -- SET default_transaction_read_only = off; SET client_encoding = &amp;#39;UTF8&amp;#39;; SET standard_conforming_strings = on; -- -- Roles -- CREATE ROLE postgres; ALTER ROLE postgres WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN REPLICATION; .</description></item><item><title>開発版 Docker &amp; Docker Registry の検証環境を作って試してみる</title><link>http://blog-ja.dtan4.net/posts/qiita-0e34a09923579e7a6670/</link><pubDate>Thu, 16 Apr 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-0e34a09923579e7a6670/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker イメージのリポジトリをを自前で管理するための Docker Private Registry というものがあります。これまで docker/docker-registry にて Python で開発されていて、現在のバージョンは 0.9.1 です。 この docker-registry、使っている Python の HTTP サーバが buggy なのか push/pull でよく失敗するという問題がありました…
ところで、この Docker Registry の次期バージョンは Go でスクラッチから開発されています。リポジトリも docker/distrbution に移りました。 最初のリリースバージョンは 2.0 になる予定で、しかもリリース日予定は 2015-04-16（たぶん西海岸時間）です。 なんだか期待が持てます :+1:
この registry v2 ですが、API も v1 -&amp;gt; v2 に上がっているので 現在リリースされている Docker 1.5 以下は対応していません（push/pull できない）。 registry v2 と同時リリースされる Docker 1.6 から対応する予定です。
=== 2015-04-16 18:40 追記 一応 README.md には Docker 1.5+ サポートするって書いてあるんですよね…
An implementation of the Docker Registry HTTP API V2 for use with docker 1.</description></item><item><title>CoreOS + flannel で複数ホスト間コンテナ通信をする</title><link>http://blog-ja.dtan4.net/posts/qiita-8f9cf40aabd2e6c9a494/</link><pubDate>Thu, 02 Apr 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-8f9cf40aabd2e6c9a494/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
CoreOS が提供する flannel を使って、複数の CoreOS マシンを跨いで Docker コンテナ同士通信できるようにする、というお話です。
flannel もともと Kubernates には似たようなホスト間通信機能がついていたのですが、Google Compute Engine (GCE) 上でしか使えないという欠点がありました。これを取り出し、汎用的に使えるようにしたのが flannel です。
また、似た機能を持つものに weave がありますが、weave は導入が少々面倒な上に相手ホストの IP を明示的に指定してあげないといけません。その点 flannel は CoreOS 上での導入が簡単で、相手の IP を知らなくてもよく透過的に利用できるという利点があります。ホストに割り振られる IP が不定である EC2 + VPC 構成でも使いやすいでしょう。
イメージ図はこんな感じです。
(from https://github.com/coreos/flannel/blob/master/packet-01.png)
試してみる 以下で紹介する CoreOS VM を含めたサンプルリポジトリです。あわせてご利用ください: dtan4/coreos-flannel-sample
cloud-config まず cloud-config はこんな感じです。flanneld.service というのを定義しています。
#cloud-config coreos: etcd: discovery: https://discovery.etcd.io/&amp;lt;token&amp;gt; addr: $public_ipv4:4001 peer-addr: $public_ipv4:7001 fleet: public-ip: $public_ipv4 flannel: interface: $public_ipv4 units: - name: etcd.service command: start - name: fleet.</description></item><item><title>Yosemite と Mavericks 間で AirDrop したい</title><link>http://blog-ja.dtan4.net/posts/qiita-3b89ed8c5226a6578b43/</link><pubDate>Thu, 12 Mar 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-3b89ed8c5226a6578b43/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Mac 同士で Wifi / Bluetooth を使ってファイルのやりとりをする AirDrop、Mavericks 同士とか Yosemite 同士というふうに OS のバージョンが一致していれば問題はないのですが、Mavericks &amp;lt;=&amp;gt; Yosemite といふうに OS をまたぐと相手のマシンが表示されません。 さっさと Yosemite に上げるという解決策もありますが、そうも行かない場合はあります。
解決策 __Yosemite 側__の AirDrop 画面で「お探しの相手が表示されませんか？」を押すと、「古い機種の Mac を検索」というボタンが出てきます。
このボタンを押すと、Mavericks マシンが AirDrop 一覧に出てきます。
REF Airdrop not working between Mavericks and Yosemite | Apple Support Communities</description></item><item><title>OS X Yosemite で Nokogiri gem を bundle install</title><link>http://blog-ja.dtan4.net/posts/qiita-34c9ebd5ce7bfa0f133b/</link><pubDate>Tue, 24 Feb 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-34c9ebd5ce7bfa0f133b/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
mac nokogiri インストール でググれば山のように出てくるけど、一応自分のやった方法も書き残しておきます。
バージョン Mac OS X 10.10.2 Ruby 2.1.5 (by rbenv) Nokogiri 1.6.3.1 bundle install する 何も考えずに bundle install したら、libiconv が無いと言われました。
Gem::Ext::BuildError: ERROR: Failed to build gem native extension. /Users/dtan4/.anyenv/envs/rbenv/versions/2.1.5/bin/ruby -r ./siteconf20150224-35319-1dn56el.rb extconf.rb Building nokogiri using packaged libraries. ----- libiconv is missing. please visit http://nokogiri.org/tutorials/installing_nokogiri.html for help with installing dependencies. ----- *** extconf.rb failed *** Could not create Makefile due to some reason, probably lack of necessary libraries and/or headers.</description></item><item><title>Ruby で HTTP ステータスコード一覧を出力するワンライナー</title><link>http://blog-ja.dtan4.net/posts/qiita-19a28356320652cd48cc/</link><pubDate>Tue, 17 Feb 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-19a28356320652cd48cc/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
$ ruby -r rack/utils -e &amp;#39;Rack::Utils::HTTP_STATUS_CODES.each_pair { |code, desc| puts &amp;#34;#{code} #{desc}&amp;#34; }&amp;#39; 100 Continue 101 Switching Protocols 102 Processing 200 OK 201 Created 202 Accepted ... 500 Internal Server Error 501 Not Implemented 502 Bad Gateway 503 Service Unavailable 504 Gateway Timeout 505 HTTP Version Not Supported 506 Variant Also Negotiates 507 Insufficient Storage 508 Loop Detected 510 Not Extended 511 Network Authentication Required HTTP ステータスコード一覧、Rack の Rack::Util モジュールに定数定義されている（コード該当箇所）ので、それを引っ張ってきているだけ。 peco にリダイレクトして絞り込みとかできる。</description></item><item><title>grep の出力をバッファさせない</title><link>http://blog-ja.dtan4.net/posts/qiita-f14f3c10d73e85ff30af/</link><pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-f14f3c10d73e85ff30af/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
grep コマンドは、何もしないと出力をバッファする（一旦溜め込む）ようになっています。
あるファイル全体とか固定のデータに対して grep する場合は特に気にならないでしょう。 しかしストリーミングデータを扱う場合、例えば何らかのログファイルを tail -f したものに対して grep すると、複数行がまとめて遅延して出力されてしまいます。 ここは元のログが出力されると（ほぼ）同時に、リアルタイムに grep 結果も出力してほしいところです。
解決策: --line-buffered オプション grep に --line-buffered オプションをつけると、出力がバッファされることなくリアルタイムに表示されるようになります！
$ tail -f /var/log/access.log | grep -E &amp;#39;\.png$&amp;#39; --line-buffered --line-buffered は、「1行単位で出力させる」というオプションです。BSD grep と GNU grep ともに用意されているので、Mac ユーザも Linux ユーザも安心です。
man 見てみましょう。
# grep (BSD grep) 2.5.1-FreeBSD --line-buffered Force output to be line buffered. By default, output is line buffered when standard output is a terminal and block buffered otherwise.</description></item><item><title>Rack 1.6 な Sinatra アプリケーションに Docker コンテナ外からアクセスできなかった</title><link>http://blog-ja.dtan4.net/posts/qiita-c7c47b845b6f15c4076f/</link><pubDate>Wed, 21 Jan 2015 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-c7c47b845b6f15c4076f/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
[2015-01-24 05:00] @5t111111 さんのコメントに基づき、Rack 1.6 のデフォルト挙動について追記 Rack 1.6.0 を使用した Sinatra アプリケーションを Docker 上で起動したところ、コンテナ外からの接続ができませんでした。EXPOSE 9292 して -p 9292:9292 しているにも関わらず、です。 とりあえずの対処法を書いておきます。
アプリケーション構成例 最小構成の Sinatra アプリケーションを Docker 上で動かすためのファイル例を Gist に上げました。
https://gist.github.com/dtan4/373907a001f3f3ebbd9c
はじめに言っておくと、Ruby のバージョンを変えること（2.1.5 にするとか）は解決になりませんでした。Ruby 2.2.0 のせいとかではない。
あと Docker のバージョンは （2015-01-21 最新の）1.4.1 です。
対処法1: Rack 1.5.2 を使う 一つ前のバージョンである Rack 1.5.2 であればこの問題は発生しません。Gemfile でバージョン指定しましょう。
gem &amp;quot;rack&amp;quot;, &amp;quot;~&amp;gt; 1.5.2&amp;quot; # or &amp;quot;= 1.5.2&amp;quot; 対処法2: rackup に -o 0.0.0.0 オプションをつける rackup --help より、
-o は ListenAddress を設定するためのオプションです。</description></item><item><title>nginx.conf で環境変数を読み込む</title><link>http://blog-ja.dtan4.net/posts/qiita-0fe6cca5487698afa68c/</link><pubDate>Fri, 12 Dec 2014 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-0fe6cca5487698afa68c/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker container で nginx を起動するときとか、nginx.conf で何かしらのパラメータを動的に設定したいことがあると思います。server_name とか。 今回は nginx.conf で何とかして環境変数を読み込む手法を紹介します。
TL;DR __env ディレクティブ__と ngx_http_perl_module (or lua_nginx_module) を使って、環境変数を nginx 変数に設定する。
Example server_name を環境変数 SERVER_NAME から動的に読み込む例を示します。
user nginx; worker_processes 4; env SERVER_NAME; http { perl_set $server_name_from_env &amp;#39;sub { return $ENV{&amp;#34;SERVER_NAME&amp;#34;}; }&amp;#39;; # ... server { server_name $server_name_from_env; # ... } } こうしておけば、docker run -e SERVER_NAME=hoge.example.com hoge/nginx みたいに都度 SERVER_NAME を設定できます。
くわしく nginx は起動時に親プロセスの環境変数を引き継ぎません。ですが、env ディレクティブを使えば特定の環境変数を nginx に引き継がせることができます。 env ディレクティブは main コンテキスト、つまり user とかと同じ階層でのみ宣言できます。</description></item><item><title>Github の緑化を続けて半年経った</title><link>http://blog-ja.dtan4.net/posts/2014-11-19-234241-hatenablog/</link><pubDate>Wed, 19 Nov 2014 23:42:41 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2014-11-19-234241-hatenablog/</guid><description>5月頃から、「継続的緑化活動」と称して Github の Contribution Graph を埋めるというのを続けています。 そしてつい先日、継続日数 (Current streak) が180日、つまり半年を越えました。 めでたい。
https://github.com/dtan4上の Graph は Public Repository への Contribution だけで構成されています。 Private Reposirtory のものは抜いてます。 自分からはログアウトしなくとも Chrome とかのシークレットウィンドウで見られる。
問題点 ただ、Contribution Graph や実際の Activity を見るとわかるように
（特に8月以降）色が薄い 一日に大した活動をしていない dotfiles 系の更新とかが多い ちゃんとしたプロダクトの開発に手を付けられていない という状況です。 Graph がすべて緑で埋まるまで残り半年、上記のことを意識して継続的に緑化していきたい所存です。
実は LT していた 今さらですが、9月に行われた RubyHiroba 2014 （投稿現在、見られないけど）で継続的緑化活動について LT していました。 本当に飛び入りで、人生初の LT をしました。 資料を載せておきます。
あと、緑化活動を行う上で目を通しておくべき Github の公式ガイドラインをおいておきます。
Why are my contributions not showing up on my profile?</description></item><item><title>peco で Docker の container ID を楽に選択する alias</title><link>http://blog-ja.dtan4.net/posts/qiita-839c85d2650e63f662b0/</link><pubDate>Mon, 20 Oct 2014 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-839c85d2650e63f662b0/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Docker 使っていると割りと container ID が必要になるケース多いと思います。 このとき一々 docker ps から container ID を探し出してコピペするのが面倒だったので、alias を定義しました。
alias -g P=&amp;#39;`docker ps | tail -n +2 | peco | cut -d&amp;#34; &amp;#34; -f1`&amp;#39; docker ps の結果を peco で絞り込みます。 これだと起動しているコンテナの ID しか取れないので、停止中のも取りたい場合は -a オプションを付ければよいです。
peco に渡す前に tail -n +2 を噛ませていますが、これは「頭から2行目以降を出力する（= 先頭行を飛ばして出力する）」というコマンドです。 docker ps は先頭行にフィールド名ヘッダが入るので、これを除去しています。
コンテナ停止 $ docker stop P コンテナのログを見る $ docker logs P nsenter を使ってコンテナに入る 予め nsenter を使えるようにしておき、.bashrc や .zshrc で docker-enter コマンドを定義しておく。
$ docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter OS X で boot2docker 経由の docker-enter を参考までに載せておきます。</description></item><item><title>DeployGate@ミクシィのインターンに参加した</title><link>http://blog-ja.dtan4.net/posts/2014-09-18-002036-hatenablog/</link><pubDate>Thu, 18 Sep 2014 00:20:36 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2014-09-18-002036-hatenablog/</guid><description>8/1 から 9/5 までの5週間、DeployGate@ミクシィのインターンシップに参加してきました。 何をやったかとか感想とかを書いておきたいと思います。
参加の経緯 逆求人イベントに参加して、そこでミクシィ人事の方々と知り合ったのが最初のきっかけです。 自分は、最初からインターンは「1ヶ月スパンの長期で・実際に業務に関わるやつ」に参加したいと考えていましたが、その点ミクシィのインターンは自分の希望にマッチしていました((他社のインターンだと、2週間くらいインターン生だけで何か作るようワークショップ形式が多い))。
Internship2014 | 株式会社ミクシィ 学生向けエンジニアイベント
募集部署は数ありますが、その中でも DeployGate は
個人的に使っていた 開発環境の改善・開発の高速化を目標とするサービスである という点で興味を持ち、配属を希望しました。
業務 社員と同じように、チームにジョインしてサービスの開発に参加できます。 自分は期間通じてサーバサイド (Rails) の開発をしていました。 新機能の追加から既存箇所の修正・改良まで、いろいろさせて頂きました。 このへん、インターンとはいえ裁量広くさせてもらえます。
DeployGate では Github を用いた Pull Request ベースの開発が行われています。 コミュニケーションツールとしては、Slack とか Sqwiggle とかを取り入れていて楽しい感じでした。 プルリク上では、自分の書いたコードをがっつりと社員さんにレビューしてもらえました。
開発にあたっては、テストファーストを心がけていました。 自分が新たに実装する箇所は勿論ですが、既存箇所に手を加えるところでもテストが不足していたら補完した上で実装に入るようにしていました。 現状どのような仕様になっているのか確認する上でも、役に立ったとは思います。
DeployGate グループ DeployGate の開発チームはミクシィの中でも独立している感じで、すごくベンチャー感((というかスタートアップ感というのか))に溢れていました。 色々自由な雰囲気でした。
インターン中に開発した機能 色々させてもらったのですが、ここで自分が開発に携わった機能を2つほど紹介しようと思います。
Invite API で DeployGate 未登録の人を招待 DeployGate には、アプリケーション開発者に他の人を招待する Invite API というものがあります。 従来は、API 経由だとすでに DeployGate に登録しているユーザしか招待できませんでした((ブラウザからは招待できた))。
今回、この Invite API で未登録の人もメールアドレスで招待できるようにしました。 API 書式は従来と変わらず、users に未登録なメールアドレスを指定できるようになっています。</description></item><item><title>peco で git のコミットハッシュを選択する alias</title><link>http://blog-ja.dtan4.net/posts/qiita-94ea5bd2f9475c72b9e9/</link><pubDate>Tue, 08 Jul 2014 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-94ea5bd2f9475c72b9e9/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
いちいち git log からコミットハッシュを探しだすのが面倒なので、alias を定義してみました。
alias -g C=&amp;#39;`git log --oneline | peco | cut -d&amp;#34; &amp;#34; -f1`&amp;#39; 例えば、git show C では peco で選択したコミットの中身をみることができます。 git reset --hard C では選択したコミットまでロールバックできます。
また、reflog から選択する alias も定義しました。
alias -g R=&amp;#39;`git reflog | peco | cut -d&amp;#34; &amp;#34; -f1`&amp;#39; git reset --hard R では peco で選択した時点まで操作履歴をロールバックできます。
See also: dot.zsh/.zshrc.peco - dtan4/dot.zsh</description></item><item><title>mado: Markdown をリアルタイムプレビューするツール作った</title><link>http://blog-ja.dtan4.net/posts/2014-06-08-220211-hatenablog/</link><pubDate>Sun, 08 Jun 2014 22:02:11 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2014-06-08-220211-hatenablog/</guid><description>Markdown のリアルタイムプレビューを行う mado というツールを作った。 世の中 Markdown Previewer なんてごまんとありそうだけど、とりあえず作った。
mado | RubyGems.org
特徴 Web ブラウザ上で Markdown をプレビュー Markdown を HTML 整形したものを Web ブラウザ上でプレビューできる。 Github Flavored Markdown に対応している。 好きなエディタで編集しつつ、横にブラウザを開いてどんな出力になるかを確認しながら使う感じ。
また、プレビューの見た目は Github 上での Markdown プレビューになるべく似せるようにしている。 Github に上げるプロジェクトの README.md を編集するのに便利ではないだろうか。
ちなみに、Github ライクな見た目の実現には github.css に手を加えたものを使用している。
Markdown ファイルの変更を検知して、プレビューをリアルタイムに更新 Markdown ファイルを編集すると、WebSocket を通じてプレビューがリアルタイムに更新される。 リロードする必要はない。
シンタックスハイライト fenced code-block (バッククォート3つで囲むやつ) に書いたコードはシンタックスハイライトされる。 ハイライトの色は Github 上での色に準じている。
相対パス画像展開 ローカル上にある画像を相対パス指定で表示することができる。
![local image](img/hoge.png) スクリーンショット インストール gem として提供している。
$ gem install mado 起動 mado はコマンドラインツールである。 編集したい Markdown ファイルを指定して起動する。</description></item><item><title>Travis CI で最新の MeCab を使う</title><link>http://blog-ja.dtan4.net/posts/qiita-c6a087666296fbd5fffb/</link><pubDate>Sat, 31 May 2014 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-c6a087666296fbd5fffb/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
Travis CI には MeCab が入っていない Travis CI の box には最初 MeCab が入っていません。 こういう場合、普通なら .travis.yml の before_install を用いて以下のように MeCab をインストールするでしょう。
before_install: - sudo apt-get update -qq - sudo apt-get install -qq mecab mecab-ipadic-utf8 libmecab-dev しかし、Travis の apt-get で入ってくる MeCab は古い (0.98) ので、例えば natto gem を使うようなアプリケーションが実行できません。 これでは Travis が赤くなって困るので、何とかして最新版 (2014/05/31 現在 0.996) を入れたいところです。
解決策: apt-get を使わず直にインストールする 最新の MeCab ソースコードを公式 Google Code から落としてきて、自家ビルド &amp;amp; インストールすれば良いのです。
基本的に公式インストールガイドの通り MeCab 本体と辞書をインストールすれば良いのですが、
before_install に書くには行が多い Travis 上ではインストール後に sudo ldconfig もする必要がある と多少面倒くさいです。 そこで、このインストール作業を一括して行うスクリプトを Gist に用意しました。 .</description></item><item><title>人生初の Pull Request を出した</title><link>http://blog-ja.dtan4.net/posts/2014-05-13-210438-hatenablog/</link><pubDate>Tue, 13 May 2014 21:04:38 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2014-05-13-210438-hatenablog/</guid><description>昨晩、GitLab (gitlabhq/gitlabhq) のドキュメントにデッドリンクを見つけたので、人生初の Pull Request を出した。
Fix dead links in ruby.md by dtan4 · Pull Request #6959 · gitlabhq/gitlabhq
最初は絶対パス指定の修正をしていたけど、相対パスのほうが好ましいですね〜というアドバイスをもらって追加コミットしたりした。 たぶん初めて squash と push -f を使った。
そして今日マージしていただけたので、めでたく one of the GitLab contributors になった。
こういう感じで OSS への貢献を増やしていきたい。
(This post was imported from https://dtan4.hatenablog.com/entry/2014/05/13/210438)</description></item><item><title>brew install boost に失敗した場合の対処法</title><link>http://blog-ja.dtan4.net/posts/qiita-9d868ee277bd37b1e30f/</link><pubDate>Thu, 08 May 2014 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-9d868ee277bd37b1e30f/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
brew install boost した時、以下のエラーを吐いてビルドが失敗した。
==&amp;gt; ./b2 --prefix=/usr/local/Cellar/boost/1.55.0_1 --libdir=/usr/local/Cellar/boost/ cp &amp;quot;bin.v2/libs/wave/build/darwin-4.2.1/release/link-static/libboost_wave.a&amp;quot; &amp;quot;/usr/local/Cellar/boost/1.55.0_1/lib/libboost_wave.a&amp;quot; ...failed updating 112 targets... ...skipped 20 targets... ...updated 12489 targets... READ THIS: https://github.com/Homebrew/homebrew/wiki/troubleshooting These open issues may also help: Boost 1.55.0 fails to build --universal (https://github.com/Homebrew/homebrew/issues/26951) &amp;quot;bottle blocked by python requirement&amp;quot; is vague in boost 1.55.0_1 upgrade (https://github.com/Homebrew/homebrew/issues/28281) どうやら Python まわりで問題が発生しているっぽい。
ここで対処法は2つある。Python support を捨てるか System Python を使うかである。
1. Python support を無効にする デフォルトでは Python support を有効にした boost がインストールされることになっている。 しかし、そもそも他のパッケージの依存物として boost を入れるのなら、Python support は必要ないことがほとんどである。 Python support を無効化してインストールすれば良い。</description></item><item><title>Markdown を Pukiwiki 記法に変換する gem 作った</title><link>http://blog-ja.dtan4.net/posts/2014-04-30-235331-hatenablog/</link><pubDate>Wed, 30 Apr 2014 23:53:31 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2014-04-30-235331-hatenablog/</guid><description>講義の関係で、しばらく Pukiwiki 上でブログっぽいのを書き続けることになった。ただ Pukiwiki 記法を新しく覚えるのが面倒なので、普段書き慣れている Markdown で書けるように変換器を書いた。
md2pukiwiki | RubyGems.org
Install $ gem install md2pukiwiki Usage md2pukiwiki というコマンドを用意してある。
引数に Markdown ファイルを指定することで、Pukiwiki 記法に変換されたテキストが標準出力に吐かれる。リダイレクトで別ファイルに出力するか、パイプ経由で pbcopy してクリップボードにコピーしたりするのが良い。
$ md2pukiwiki sample.md Ruby コード内で変換を行うには、以下のように書く。
require &amp;#34;md2pukiwiki&amp;#34; pukiwiki = Md2Pukiwiki.convert(markdown) Example この Markdown が
# header * list1 * l**is**t2 * list2.1 ## subheader 1. nlist1 2. nl*is*t2 1. nlist2.1 こういう Pukiwiki 記法に変換される。
*header - list1 - l''is''t2 -- list2.1 **subheader + nlist1 + nl'''is'''t2 ++ nlist2.</description></item><item><title>VAIO Pro に Arch Linux をインストールする</title><link>http://blog-ja.dtan4.net/posts/2013-12-04-015333-hatenablog/</link><pubDate>Wed, 04 Dec 2013 01:53:33 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-12-04-015333-hatenablog/</guid><description>2014/02/20 再インストールに伴い数カ所修正
===
VAIO Pro 11 を買ったので、これまでの環境と同じく Arch Linux を入れました。（これまでは ArchBang を使っていたので）素の Arch を入れるのは初めて。
なお、以下の作業は 2013-10-28 時点のものです。現在でも大体このままで大丈夫だと思いますが、まずいところは ArchWiki など参照して適宜修正してください。
準備するもの VAIO Pro 有線ネットワーク環境 USB 有線 LAN アダプタ DVD-R 4枚（or 同等の容量分の光学メディアか USB メモリ） 光学メディアを使うなら USB 外付けドライブ リカバリメディア用 USB メモリ LiveUSB 用 Arch Linux LiveUSB を作る （Mac or Linux 上で作業していると仮定） iso イメージをダウンロード 日本におるなら jaist あたりのミラーを使うべき USB メモリを刺す すぐに sudo dmesg | tail -20 sda:sda1 とか表示されたのを覚えておく iso を USB メモリに焼く dd if=/path/to/iso of=/dev/sdX bs=1M sdX はさっき覚えたやつ Windows を処分する 万一のために、リカバリディスクを作っておく VAIO Update をかけて BIOS とか色々最新化しておく ASSIST ボタンを押すか VAIO Care (Desktop) を開く リカバリメディアの作成をする フラッシュメモリか、外付け光学ドライブ + 光学メディアが必要 DVD-R 4.</description></item><item><title>magit でコミットするときに新しいウィンドウを立ち上げないようにする</title><link>http://blog-ja.dtan4.net/posts/qiita-658a8a7ca06aa8c2da4c/</link><pubDate>Fri, 11 Oct 2013 00:00:00 +0000</pubDate><guid>http://blog-ja.dtan4.net/posts/qiita-658a8a7ca06aa8c2da4c/</guid><description>この記事はQiitaの記事をエクスポートしたものです。内容が古くなっている可能性があります。
(2019-03-07 追記)
.emacs.d 大掃除をやってて気づいたのですが、このハックは現代の Emacs + magit では不要になっていました。
GNU Emacs 26.1 (build 1, x86_64-apple-darwin18.0.0, Carbon Version 158 AppKit 1671) of 2018-11-18 magit-20190306.413 (以下 2013-10-11 時点での投稿)
2ヶ月ほど前に magit のコミット周りの実装が大きく変わりました。それまではコミットメッセージの入力をミニバッファで行っていましたが、この変更に伴い git-commit-mode というメジャーモードを用いて入力、つまり一つのバッファを占有して行うようになりました。
本来この git-commit-mode は 同じ ウィンドウ内の別バッファに開くことが意図されており、Linux 版ではこの通りの挙動を示します。 しかし、Mac 版 (Cocoa) Emacs では 新しく ウィンドウを開いて（もう一つ Emacs を起動して）そこに git-commit-mode を開くという挙動を示し、大変面倒くさい感じになっていました。
2ヶ月間この挙動に悩まされていましたが、この度改善するための設定を発見したため、ここに共有します。
Mac でも同一ウィンドウ内でコミットアクションを完結させる /Application に Emacs.app を置いた場合は
(set-variable &amp;#39;magit-emacsclient-executable &amp;#34;/Applications/Emacs.app/Contents/MacOS/bin/emacsclient&amp;#34;) Homebrew で Emacs をインストールした場合は
(set-variable &amp;#39;magit-emacsclient-executable &amp;#34;/usr/local/Cellar/emacs/24.3/bin/emacsclient&amp;#34;) を init.el などに追記しましょう。
これで次回から git-commit-mode は 同じ ウィンドウ内の別バッファに立ち上がるようになります。c を2回押したあと、ウィンドウを切り替えてメッセージ入れて C-c C-c したら手動でウィンドウを閉じる・・・といった煩わしさから開放されます。</description></item><item><title>nowtv: 現在放送中の番組一覧を確認するコマンド作った</title><link>http://blog-ja.dtan4.net/posts/2013-10-02-195528-hatenablog/</link><pubDate>Wed, 02 Oct 2013 19:55:28 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-10-02-195528-hatenablog/</guid><description>2015-01-24 22:00 追記 利用させてもらっていた API が廃止されたようで、nowtv は現在データを取得できず使用することができません。 とりあえず gem の公開と Github でのソースの公開、そして本記事の公開は続けておきますが、コマンド自体は何もできないことをご留意ください。
以下は nowtv 公開時点での記事です。
現在放送中の番組を確認できるコマンドラインツール nowtv を作った。ご利用ください。
背景 今テレビで何放送しているかな、というのを確認するのに一々ブラウザ立ちあげて番組表サイトにアクセスするのが面倒だった。コンソール上でサクッと確認したかったので作ってみた。
インストール RubyGems で配布しているので gem install nowtv
使い方 nowtv を呼ぶと、現在放送しているテレビ番組一覧を表示する。デフォルトでは東京都の番組表。
$ nowtv NHK総合: 仕事ハッケン伝 [16:05 -&amp;gt; 16:55] NHK Eテレ: 第68回国民体育大会～スポーツ祭東京2013～ [16:00 -&amp;gt; 17:00] 日本テレビ: 特選ぶらり途中下車の旅 [15:55 -&amp;gt; 16:53] テレビ朝日: 相棒セレクション [15:57 -&amp;gt; 16:53] TBSテレビ: Nスタ [15:50 -&amp;gt; 19:00] テレビ東京: L4YOU! [16:00 -&amp;gt; 16:52] フジテレビ: 踊る大捜査線 [15:50 -&amp;gt; 16:50] TOKYO MX: スマイルプリキュア!</description></item><item><title>東京アメッシュをコマンドラインから利用できるツール ramesh を作った</title><link>http://blog-ja.dtan4.net/posts/2013-07-15-212850-hatenablog/</link><pubDate>Mon, 15 Jul 2013 21:28:50 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-07-15-212850-hatenablog/</guid><description>昨日は多摩の方まで走りに行ったら、帰りがけにゲリラ豪雨にあってしまった。尾根幹の陸橋下で30分くらい雨宿りしとった。
東京都下水道局が提供する東京アメッシュという素晴らしいサービスが有る。現在から2時間前までの5分間隔で、南関東一帯の降水量を確認することができる。特に都内の観測範囲は緻密。ゲリラ豪雨が発生するとその地点が局地的に赤くなるので、「ゲリラ豪雨が近づいてきそうだ」という予測を立てるのも容易。
で、この素晴らしきサービスをコマンドラインから利用できるツール ramesh を作った。アメッシュ確認するのに一々ブラウザ開きたくない人ご利用ください。
なにこれ 東京アメッシュが提供している降水量レーダー画像をダウンロードするツール。現在の画像はもちろん、過去に遡っての画像取得も可能。
インストール ImageMagick が必要。画像合成処理をしているので。
ramesh は gem として公開しているので普通に
$ gem install ramesh でインストールできる。
つかいかた 引数を指定しないと、現在のレーダー画像をダウンロードする。
$ ramesh 過去の画像を取得することもできる。分は0-120の間、5分単位で指定する必要がある。以下の例だと90分前の画像をダウンロードする。
$ ramesh 90 範囲を指定して、複数枚の画像を取得することもできる。以下の例だと50分前から120分前まで5分間隔で、合計15枚の画像をダウンロードする。
$ ramesh 50-120 ソースコード github - dtan4/ramesh
技術情報 ブラウザに表示されるアメッシュのレーダー画像は、3枚の画像が重なりあったものである。上から順に、
都県名・都県境の画像 /map/msk000.png 降水量メッシュ画像 /mesh/000/yyyyMMddhhmm.gif 地形図 /map/map000.png このうち、上2つは背景透過がなされているので、重ねるといい具合に表示できる。ramesh は3枚それぞれをダウンロードしてきて、それらを合成したものを1枚の gif として保存している。
また、現在アメッシュのサーバに保存されているメッシュ画像の一覧は以下の JavaScript ファイルに書いてある。これをパースすれば画像ファイル名をとれる。
http://tokyo-ame.jwa.or.jp/scripts/mesh_index.js
余談 今は自宅鯖で ramesh を cron で回してデータ蓄積しとる。10日間で3300枚、770MB 超。時折溜めた分引っ張ってきてパラパラ漫画見たくアニメーション作ったりしとる。
初めての gem なので、先人の書いた gem を色々参考にしながら書いてみた。とりあえず大体の流れはつかめた感じ。
(This post was imported from https://dtan4.</description></item><item><title>GPS データ (GPX) から移動距離を求める</title><link>http://blog-ja.dtan4.net/posts/2013-06-10-013724-hatenablog/</link><pubDate>Mon, 10 Jun 2013 01:37:24 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-06-10-013724-hatenablog/</guid><description>GPS データから走行距離を計算したくて、緯度経度を用いた距離計算法を調べてみた。そしてスクリプト書いた。
2点間距離を求める 緯度経度を用いて距離を測定するには、ヒュベニの公式を使うのがわりとポピュラーそうだった。この式は、3D地図ソフトのカシミール3Dで使われていたりする。
カシミール / 計算式に載っている式を転載すると、
D=sqrt((M*dP)*(M*dP)+(N*cos(P)*dR)*(N*cos(P)*dR)) D: ２点間の距離(m) P: ２点の平均緯度 dP: ２点の緯度差 dR: ２点の経度差 M: 子午線曲率半径 N: 卯酉線曲率半径 M=6334834/sqrt((1-0.006674*sin(P)*sin(P))^3) N=6377397/sqrt(1-0.006674*sin(P)*sin(P)) こんな感じ。
もう少し詳しい解説はこのページにのってる。今回はここを参考にした。
二地点の緯度・経度からその距離を計算する（日本は山だらけ〜）
基本上ページ Fig.1 の通りにプログラムを書けばいいけど、ヒュベニの公式で用いる緯度経度はラジアンであるのに注意しなければならない（ハマった）。GPS で記録される緯度経度は勿論度なので変換する必要がある。
# deg（度）から rad（ラジアン）を求める rad = deg * Math::PI / 180 高校数学を思い出す。
あと、子午線曲率半径の算出に長半径（赤道半径）・卯酉線曲率半径を求めるのに短半径（極半径）が必要だけど、今回は GPS に使われるらしい WGS84 基準のパラメータを用いた。
測定誤差 地球は楕円体だしということで、やっぱり計算結果に誤差は出てくる。下のページで検証がなされている。
緯度経度から2点間の距離を求める | ぷちのいず
上のページによると、ヒュベニの公式を用いた場合は50km以上から誤差が大きくなるらしい。今回は自転車の走行距離を（主に）算出したいので、結果は高々200kmといったところ。まあ問題ないということにした。
GPX ファイルから移動距離を計算する 以上の計算を、GPX ファイル（GPS データを格納する XML）に記録されたトラックポイント間に対して行う。
GPX ファイルの中身は XML になっている。構造の説明は置いといて、トラックポイントの緯度経度は trkpt タグに属性値として記録されている。こんな感じ。
&amp;lt;trkpt lat=&amp;#34;35.765263255&amp;#34; lon=&amp;#34;139.867893811&amp;#34;&amp;gt; こっから lat （緯度）と lng （経度）を正規表現抽出して配列に格納。全部抽出し終わったら先頭から各要素間の距離を求めていく。ラジアン変換も忘れずに。その総和が移動距離になる。</description></item><item><title>rbenv でインストールした Ruby を Emacs で使う</title><link>http://blog-ja.dtan4.net/posts/2013-04-08-133458-hatenablog/</link><pubDate>Mon, 08 Apr 2013 13:34:58 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-04-08-133458-hatenablog/</guid><description>Mac では rbenv でインストールした Ruby 2.0.0p0 を使っとるけど、Emacs の smart-compile が呼ぶ Ruby は /usr/bin/ruby つまり Ruby 1.8.7 で不便やった。
rbenv の Ruby を使うには 、Emacs の環境変数 PATH に rbenv のパス（ターミナルで which ruby してでるやつ）を追加すれば良い。 .emacs なり init.el なりに以下を記述する。
(setenv &amp;#34;PATH&amp;#34; (concat (expand-file-name &amp;#34;~/.rbenv/shims:&amp;#34;) (getenv &amp;#34;PATH&amp;#34;))) 参考 http://d.hatena.ne.jp/gan2/20120528/1338191267
(This post was imported from https://dtan4.hatenablog.com/entry/2013/04/08/133458)</description></item><item><title>uim-mozc 周りのインストールで躓いた</title><link>http://blog-ja.dtan4.net/posts/2013-03-28-023536-hatenablog/</link><pubDate>Thu, 28 Mar 2013 02:35:36 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-03-28-023536-hatenablog/</guid><description>Arch Linux での日本語入力には uim-mozc を常用。 さっき久々に yaourt -Syu して再起動したら日本語入力できやんくなっとった。 とりあえず uim-mozc と uim を再インストールしてみることにした。
uimの再インストールは問題なかったけど、yaourt -S uim-mozc で uim-mozc をインストールし直そうとしたら、ビルド段階で
&amp;ldquo;/etc/profile.d/qt4.sh&amp;rdquo; が見つかりません
みたいなこと言われた。 別の AUR パッケージのコメントによると、最新バージョン (qt4 4.8.4-16) では qt4.sh が廃止されたらしい（上から2つめのコメント）。
PKGBUILD を編集したら何とかなりそうやけど、よくわからんのでネットから qt4.sh を落としてきた。&amp;ldquo;qt4.sh&amp;rdquo; でググった一発目のをそのまま /etc/profile.d/ に突っ込めばOK。slackware やけどキニシナイ。↓
http://mirrors.slackware.com/slackware/slackware_source/l/qt/profile.d/qt4.sh
これでビルドが通る、はず。
はず、というのも上のやり取りの中で mozc-ut モジュールの存在を知ったので、最後はそっちで入れた。
yaourt -S mozc-utで、PKGBUILD の _uim-mozc= 行をコメントアウトする。 終わったら画面の指示通り sudo uim-module-manager --register mozc して再起動すれば日本語入力できるようになる。 Input Japanese using uim (日本語) - ArchWiki 参照
ArchWiki はやはり痒いところに手が届く。</description></item><item><title>2ch を JSON に変換するサーバ作った</title><link>http://blog-ja.dtan4.net/posts/2013-03-14-143725-hatenablog/</link><pubDate>Thu, 14 Mar 2013 14:37:25 +0900</pubDate><guid>http://blog-ja.dtan4.net/posts/2013-03-14-143725-hatenablog/</guid><description>2ch のデータをパースして JSON に変換する API サーバ 2son を作った。 http://twoson.herokuapp.com/
Heroku 便利
できること 以下のデータを JSON に変換できる 板一覧 (bbstable) スレッド一覧 (subject) スレッド (thread) dat 落ちスレッドにも対応 コールバック関数を指定すれば、JSONP を取得することもできる。 仕様 トップページで API の呼び方、返ってきた JSON の書式を説明してある。 http://twoson.herokuapp.com/
いろいろ Ruby 1.9.3 で開発。Ruby の勉強がてら組んでみた。
データ取得 ブラウザで表示する形式、つまり read.cgi を通してスレッドを取得するのはサーバーに負荷がかかるし、またパースするもの面倒やからよろしくない。したがって、データが欲しい時場合スレッド一覧は subject.txt、スレッドは dat ファイルを直接読みに行くのが推奨される。これらのファイルは1行1（スレッド | レス）で、デリミタは &amp;lt;&amp;gt; になっとってパースもしやすい。このへんは開発資料で詳しく解説してある。
また、通信量低減のためにレスポンスは gzip でもらう。リクエストヘッダに
&amp;quot;Accept-Encoding&amp;quot;: &amp;quot;gzip&amp;quot; を付与する。もちろんもらった後は解凍処理が必要。
あと、データのエンコーディングは Shift-JIS やから nkf で UTF-8 に変えると良い。必要なら。</description></item></channel></rss>